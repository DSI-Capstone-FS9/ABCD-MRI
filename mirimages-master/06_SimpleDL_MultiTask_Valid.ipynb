{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 48054,
     "status": "ok",
     "timestamp": 1573636583219,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": -60
    },
    "id": "2mU_ZLUH5jz4",
    "outputId": "c4cbc445-56dd-49df-de87-c34e18da5f6c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import glob\n",
    "import nibabel as nib\n",
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from mricode.utils import log_textfile\n",
    "from mricode.utils import copy_colab\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nH4XzW8C5yhH"
   },
   "outputs": [],
   "source": [
    "path_output = './'\n",
    "path_tfrecords = '/data2/res64/down/'\n",
    "path_csv = '/data2/csv/'\n",
    "#path_csv = '/content/drive/My Drive/Capstone/05_Data/01_Label/'\n",
    "filename_res = {'train': 'intell_residual_train.csv', 'val': 'intell_residual_valid.csv', 'test': 'intell_residual_test.csv'}\n",
    "filename_norm = {'train': 'intell_train.csv', 'val': 'intell_valid.csv', 'test': 'intell_test.csv'}\n",
    "filename_fluid = {'train': 'training_fluid_intelligence_sri.csv', 'val': 'validation_fluid_intelligence_sri.csv', 'test': 'test_fluid_intelligence_sri.csv'}\n",
    "filename_final = filename_res\n",
    "sample_size = 'site16_allimages'\n",
    "batch_size = 8\n",
    "onlyt1 = False\n",
    "t1_mean = 0.35196779465675354 \n",
    "t2_mean = 0.5694633522033692\n",
    "t1_std = 0.8948413240464094\n",
    "t2_std = 1.2991791534423829"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZzpJsO5Rx_LM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "96CI6bJ26JIo"
   },
   "outputs": [],
   "source": [
    "def return_iter(path, sample_size, batch_size=8, onlyt1=False):\n",
    "  # Some definitions\n",
    "  if onlyt1:\n",
    "    read_features = {\n",
    "      't1': tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "      'subjectid': tf.io.FixedLenFeature([], dtype=tf.string)\n",
    "    }\n",
    "  else:\n",
    "    read_features = {\n",
    "      't1': tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "      't2': tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "      'subjectid': tf.io.FixedLenFeature([], dtype=tf.string)\n",
    "    }\n",
    "  def _parse_(serialized_example, decoder = np.vectorize(lambda x: x.decode('UTF-8')), onlyt1=False):\n",
    "    example = tf.io.parse_single_example(serialized_example, read_features)\n",
    "    subjectid = example['subjectid']\n",
    "    if not(onlyt1):\n",
    "      t1 = tf.expand_dims(tf.reshape(tf.io.decode_raw(example['t1'], tf.int8), (64,64,64)), axis=-1)\n",
    "      t2 = tf.expand_dims(tf.reshape(tf.io.decode_raw(example['t2'], tf.float32), (64,64,64)), axis=-1)\n",
    "      return ({'t1': t1, 't2': t2, 'subjectid': subjectid})\n",
    "    else:\n",
    "      t1 = tf.expand_dims(tf.reshape(tf.io.decode_raw(example['t1'], tf.int8), (256,256,256)), axis=-1)\n",
    "      return ({'t1': t1, 'subjectid': subjectid})\n",
    "  \n",
    "  train_ds = tf.data.TFRecordDataset(path +'t1t2_train_' + str(sample_size) + '_v4.tfrecords')\n",
    "  val_ds = tf.data.TFRecordDataset(path + 't1t2_val_' + str(sample_size) + '_v4.tfrecords')\n",
    "  test_ds = tf.data.TFRecordDataset(path + 't1t2_test_' + str(sample_size) + '_v4.tfrecords')\n",
    "  train_iter = train_ds.map(lambda x:_parse_(x, onlyt1=onlyt1)).shuffle(True).batch(batch_size)\n",
    "  val_iter = val_ds.map(lambda x:_parse_(x, onlyt1=onlyt1)).batch(batch_size)\n",
    "  test_iter = test_ds.map(lambda x:_parse_(x, onlyt1=onlyt1)).batch(batch_size)\n",
    "  return train_iter, val_iter, test_iter\n",
    "\n",
    "def return_csv(path, filenames={'train': 'intell_train.csv', 'val': 'intell_valid.csv', 'test': 'intell_test.csv'}, fluid = False):\n",
    "  train_df = pd.read_csv(path + filenames['train'])\n",
    "  val_df = pd.read_csv(path + filenames['val'])\n",
    "  test_df = pd.read_csv(path + filenames['test'])\n",
    "  norm = None\n",
    "  if fluid:\n",
    "    train_df.columns = ['subjectkey', 'fluid_res', 'fluid']\n",
    "    val_df.columns = ['subjectkey', 'fluid_res', 'fluid']\n",
    "    test_df.columns = ['subjectkey', 'fluid_res', 'fluid']\n",
    "  train_df['subjectkey'] = train_df['subjectkey'].str.replace('_', '')\n",
    "  val_df['subjectkey'] = val_df['subjectkey'].str.replace('_', '')\n",
    "  test_df['subjectkey'] = test_df['subjectkey'].str.replace('_', '')\n",
    "  if not(fluid):\n",
    "    for df in [train_df, val_df, test_df]:\n",
    "      df['race.ethnicity'] = df['race.ethnicity'] - 1\n",
    "      df['married'] = df['married'] - 1\n",
    "      df['high.educ_group'] = 0\n",
    "      df.loc[(train_df['high.educ']>=11) & (df['high.educ']<=12),'high.educ_group'] = 1\n",
    "      df.loc[(train_df['high.educ']>=13) & (df['high.educ']<=13),'high.educ_group'] = 2\n",
    "      counter = 3\n",
    "      for i in range(14,22):\n",
    "        df.loc[(df['high.educ']>=i) & (df['high.educ']<=i),'high.educ_group'] = counter\n",
    "      df['income_group'] = 0\n",
    "      counter = 1\n",
    "      for i in range(4,11):\n",
    "        df.loc[(df['income']>=i) & (df['income']<=i),'income_group'] = counter\n",
    "        counter += 1\n",
    "    norm = {}\n",
    "    for col in ['BMI', 'age', 'vol', 'weight', 'height', 'nihtbx_fluidcomp_uncorrected', 'nihtbx_cryst_uncorrected', \n",
    "                'nihtbx_pattern_uncorrected', 'nihtbx_picture_uncorrected', \n",
    "                'nihtbx_list_uncorrected', 'nihtbx_flanker_uncorrected',\n",
    "                'nihtbx_picvocab_uncorrected', 'nihtbx_cardsort_uncorrected',\n",
    "                'nihtbx_totalcomp_uncorrected', 'nihtbx_reading_uncorrected']:\n",
    "      mean = train_df[col].mean()\n",
    "      std = train_df[col].std()\n",
    "      train_df[col + '_norm'] = (train_df[col]-mean)/std\n",
    "      val_df[col + '_norm'] = (val_df[col]-mean)/std\n",
    "      test_df[col + '_norm'] = (test_df[col]-mean)/std\n",
    "      norm[col] = {'mean': mean, 'std': std}\n",
    "  return train_df, val_df, test_df, norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4520,
     "status": "ok",
     "timestamp": 1573636640714,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": -60
    },
    "id": "B-rSS9vT6TuF",
    "outputId": "f5b43cbc-7d59-4c7c-b6d6-78882b1ef3e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function return_iter.<locals>._parse_ at 0x7f2e0aac3488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: \n",
      "WARNING: Entity <function return_iter.<locals>._parse_ at 0x7f2e0aac3488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: \n"
     ]
    }
   ],
   "source": [
    "train_iter, val_iter, test_iter = return_iter(path_tfrecords, sample_size, batch_size, onlyt1=onlyt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_WxRhswDxB6a"
   },
   "outputs": [],
   "source": [
    "a = next(iter(train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lJ0VnyEzBAes"
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "  t1_mean = 0.\n",
    "  t1_std = 0.\n",
    "  t2_mean = 0.\n",
    "  t2_std = 0.\n",
    "  n = 0.\n",
    "  for b in train_iter:\n",
    "      t1_mean += np.mean(b['t1'])\n",
    "      t1_std += np.std(b['t1'])\n",
    "      t2_mean += np.mean(b['t2'])\n",
    "      t2_std += np.std(b['t2'])\n",
    "      n += np.asarray(b['t1']).shape[0]\n",
    "\n",
    "  t1_mean /= n\n",
    "  t1_std /= n\n",
    "  t2_mean /= n\n",
    "  t2_std /= n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2924,
     "status": "ok",
     "timestamp": 1573636640716,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": -60
    },
    "id": "mSwhEqDPM_r8",
    "outputId": "14a4ac0b-9587-4776-fc64-1e008f0c5c31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.35196779465675354,\n",
       " 0.8948413240464094,\n",
       " 0.5694633522033692,\n",
       " 1.2991791534423829)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1_mean, t1_std, t2_mean, t2_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PAyV5ktlA6K1"
   },
   "outputs": [],
   "source": [
    "train_df, val_df, test_df, norm_dict = return_csv(path_csv, filename_final, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3147,
     "status": "ok",
     "timestamp": 1573636641787,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": -60
    },
    "id": "0xYy4XUyVBeC",
    "outputId": "a6a19d59-31ff-4064-f1dc-952befcce4b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BMI': {'mean': 18.681548127052135, 'std': 4.193043131845343},\n",
       " 'age': {'mean': 119.00325844623563, 'std': 7.479129774017182},\n",
       " 'height': {'mean': 55.25173666322929, 'std': 3.152756181679028},\n",
       " 'nihtbx_cardsort_uncorrected': {'mean': 0.01902727147573316,\n",
       "  'std': 0.92710655806542},\n",
       " 'nihtbx_cryst_uncorrected': {'mean': 0.007018628014748754,\n",
       "  'std': 0.7845373584638602},\n",
       " 'nihtbx_flanker_uncorrected': {'mean': 0.02188780794049048,\n",
       "  'std': 0.9070917080607726},\n",
       " 'nihtbx_fluidcomp_uncorrected': {'mean': 0.020178243913565427,\n",
       "  'std': 0.86606123778624},\n",
       " 'nihtbx_list_uncorrected': {'mean': 0.00625176016120734,\n",
       "  'std': 0.8898550695735616},\n",
       " 'nihtbx_pattern_uncorrected': {'mean': 0.020721412569885096,\n",
       "  'std': 0.9486618556882954},\n",
       " 'nihtbx_picture_uncorrected': {'mean': 0.0005782175223803825,\n",
       "  'std': 0.9577989703304521},\n",
       " 'nihtbx_picvocab_uncorrected': {'mean': 0.0068509109986280275,\n",
       "  'std': 0.8038465951211212},\n",
       " 'nihtbx_reading_uncorrected': {'mean': 0.0027847502208883574,\n",
       "  'std': 0.8572703419965433},\n",
       " 'nihtbx_totalcomp_uncorrected': {'mean': 0.016971206631452577,\n",
       "  'std': 0.7866686549175077},\n",
       " 'vol': {'mean': 0.013939557398902416, 'std': 1.001699783217792},\n",
       " 'weight': {'mean': 81.91536668875837, 'std': 23.321845390211728}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2660,
     "status": "ok",
     "timestamp": 1573636641788,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": -60
    },
    "id": "_SVRoaUTgv1O",
    "outputId": "7b86ff58-14d7-488a-9b56-4962b095211e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subjectkey                           NDARINVZZZNB0XC\n",
       "age                                              131\n",
       "female                                             1\n",
       "race.ethnicity                                     4\n",
       "high.educ                                         21\n",
       "income                                            10\n",
       "married                                            5\n",
       "abcd_site                                         22\n",
       "vol                                          3.96307\n",
       "height                                            81\n",
       "weight                                           272\n",
       "BMI                                          54.9929\n",
       "nihtbx_fluidcomp_uncorrected                 3.14844\n",
       "nihtbx_cryst_uncorrected                     3.46236\n",
       "nihtbx_pattern_uncorrected                   3.20819\n",
       "nihtbx_picture_uncorrected                   2.91261\n",
       "nihtbx_list_uncorrected                      2.87982\n",
       "nihtbx_flanker_uncorrected                   2.60289\n",
       "nihtbx_picvocab_uncorrected                  3.48154\n",
       "nihtbx_cardsort_uncorrected                  2.92297\n",
       "nihtbx_totalcomp_uncorrected                 3.04367\n",
       "nihtbx_reading_uncorrected                   3.87485\n",
       "high.educ_group                                    3\n",
       "income_group                                       7\n",
       "BMI_norm                                     8.65991\n",
       "age_norm                                     1.60403\n",
       "vol_norm                                     3.94243\n",
       "weight_norm                                   8.1505\n",
       "height_norm                                  8.16691\n",
       "nihtbx_fluidcomp_uncorrected_norm            3.61205\n",
       "nihtbx_cryst_uncorrected_norm                 4.4043\n",
       "nihtbx_pattern_uncorrected_norm              3.35996\n",
       "nihtbx_picture_uncorrected_norm              3.04033\n",
       "nihtbx_list_uncorrected_norm                 3.22926\n",
       "nihtbx_flanker_uncorrected_norm              2.84536\n",
       "nihtbx_picvocab_uncorrected_norm             4.32258\n",
       "nihtbx_cardsort_uncorrected_norm             3.13226\n",
       "nihtbx_totalcomp_uncorrected_norm            3.84749\n",
       "nihtbx_reading_uncorrected_norm              4.51674\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FmJMaxLJLIgE"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv3D\n",
    "from tensorflow import nn\n",
    "from tensorflow.python.ops import nn_ops\n",
    "from tensorflow.python.framework import tensor_shape\n",
    "from tensorflow.python.keras.engine.base_layer import InputSpec\n",
    "from tensorflow.python.keras.utils import conv_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eTk95ptFV5oN"
   },
   "outputs": [],
   "source": [
    "cat_cols = {'female': 2, 'race.ethnicity': 5, 'high.educ_group': 4, 'income_group': 8, 'married': 6}\n",
    "#cat_cols = {}\n",
    "num_cols = [x for x in list(val_df.columns) if '_norm' in x]\n",
    "#num_cols = num_cols[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1134,
     "status": "ok",
     "timestamp": 1573636642235,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": -60
    },
    "id": "gSh5zfycjI7A",
    "outputId": "b7a137d4-fb48-413e-9307-fcab56fc28d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BMI_norm',\n",
       " 'age_norm',\n",
       " 'vol_norm',\n",
       " 'weight_norm',\n",
       " 'height_norm',\n",
       " 'nihtbx_fluidcomp_uncorrected_norm',\n",
       " 'nihtbx_cryst_uncorrected_norm',\n",
       " 'nihtbx_pattern_uncorrected_norm',\n",
       " 'nihtbx_picture_uncorrected_norm',\n",
       " 'nihtbx_list_uncorrected_norm',\n",
       " 'nihtbx_flanker_uncorrected_norm',\n",
       " 'nihtbx_picvocab_uncorrected_norm',\n",
       " 'nihtbx_cardsort_uncorrected_norm',\n",
       " 'nihtbx_totalcomp_uncorrected_norm',\n",
       " 'nihtbx_reading_uncorrected_norm']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1j3q7l7DDWSq"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "\n",
    "class MyDNN(Model):\n",
    "  def __init__(self, cat_cols, num_cols):\n",
    "    super(MyDNN, self).__init__()\n",
    "    self.cat_cols = cat_cols\n",
    "    self.num_cols = num_cols\n",
    "    self.ac = tf.keras.layers.ReLU()\n",
    "    self.maxpool = tf.keras.layers.MaxPool3D(pool_size=(2, 2, 2), data_format='channels_last')\n",
    "    self.conv1 = tf.keras.layers.Conv3D(\n",
    "        filters = 1,\n",
    "        kernel_size = 3,\n",
    "        padding='valid',\n",
    "        data_format='channels_last'\n",
    "    )\n",
    "    self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "    self.conv2 = tf.keras.layers.Conv3D(\n",
    "        filters = 16,\n",
    "        kernel_size = 3,\n",
    "        padding='valid',\n",
    "        data_format='channels_last'\n",
    "    )\n",
    "    self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "    self.conv3 = tf.keras.layers.Conv3D(\n",
    "        filters = 32,\n",
    "        kernel_size = 3,\n",
    "        padding='valid',\n",
    "        data_format='channels_last'\n",
    "    )\n",
    "    self.bn3 = tf.keras.layers.BatchNormalization()\n",
    "    self.conv4 = tf.keras.layers.Conv3D(\n",
    "        filters = 256,\n",
    "        kernel_size = 3,\n",
    "        padding='valid',\n",
    "        data_format='channels_last'\n",
    "    )\n",
    "    self.bn4 = tf.keras.layers.BatchNormalization()\n",
    "    self.fc = {}\n",
    "    for k in list(self.cat_cols.keys()):\n",
    "      self.fc[k] = tf.keras.Sequential([\n",
    "                                        tf.keras.layers.Dense(256, activation='relu'),\n",
    "                                        tf.keras.layers.BatchNormalization(),\n",
    "                                        tf.keras.layers.Dense(self.cat_cols[k], activation='softmax')\n",
    "                                        ])\n",
    "    for i in range(len(self.num_cols)):\n",
    "      self.fc[self.num_cols[i]] = tf.keras.Sequential([\n",
    "                                        tf.keras.layers.Dense(256, activation='relu'),\n",
    "                                        tf.keras.layers.BatchNormalization(),\n",
    "                                        tf.keras.layers.Dense(1)\n",
    "                                        ])\n",
    "    #self.fc1 = tf.keras.Sequential([\n",
    "    #                                    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    #                                    tf.keras.layers.BatchNormalization(),\n",
    "    #                                    tf.keras.layers.Dense(1)\n",
    "    #                                    ])\n",
    "    #self.fc2 = tf.keras.Sequential([\n",
    "    #                                tf.keras.layers.Dense(256, activation='relu'),\n",
    "    #                                tf.keras.layers.BatchNormalization(),\n",
    "    #                                tf.keras.layers.Dense(1)\n",
    "    #                                ])\n",
    "    #self.fc3 = tf.keras.Sequential([\n",
    "    #                                tf.keras.layers.Dense(256, activation='relu'),\n",
    "    #                                tf.keras.layers.BatchNormalization(),\n",
    "    #                                tf.keras.layers.Dense(1)\n",
    "    #                                ])\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = self.bn1(x)\n",
    "    x = self.ac(x)\n",
    "    x = self.maxpool(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.bn2(x)\n",
    "    x = self.ac(x)\n",
    "    x = self.maxpool(x)\n",
    "    x = self.conv3(x)\n",
    "    x = self.bn3(x)\n",
    "    x = self.ac(x)\n",
    "    x = self.maxpool(x)\n",
    "    x = self.conv4(x)\n",
    "    x = self.bn4(x)\n",
    "    x = self.ac(x)\n",
    "    x = tf.keras.layers.GlobalAveragePooling3D()(x)\n",
    "    out = {}\n",
    "    for k in list(self.fc.keys()):\n",
    "      out[k] = self.fc[k](x)\n",
    "    #['age_norm', 'vol_norm', 'weight_norm']\n",
    "    #out['age_norm'] = self.fc1(x)\n",
    "    #out['vol_norm'] = self.fc2(x)\n",
    "    #out['weight_norm'] = self.fc3(x)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pwzdY28gkCdN"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "\n",
    "class MyDNN(Model):\n",
    "  def __init__(self, cat_cols, num_cols):\n",
    "    super(MyDNN, self).__init__()\n",
    "    self.cat_cols = cat_cols\n",
    "    self.num_cols = num_cols\n",
    "    self.ac = tf.keras.layers.ReLU()\n",
    "    self.maxpool = tf.keras.layers.MaxPool3D(pool_size=(2, 2, 2), data_format='channels_last')\n",
    "    self.conv1 = tf.keras.layers.Conv3D(\n",
    "        filters = 32,\n",
    "        kernel_size = 3,\n",
    "        padding='valid',\n",
    "        data_format='channels_last',\n",
    "        input_shape = (64,64,64,2)\n",
    "    )\n",
    "    self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "    self.conv2 = tf.keras.layers.Conv3D(\n",
    "        filters = 64,\n",
    "        kernel_size = 3,\n",
    "        padding='valid',\n",
    "        data_format='channels_last'\n",
    "    )\n",
    "    self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "    self.conv3 = tf.keras.layers.Conv3D(\n",
    "        filters = 128,\n",
    "        kernel_size = 3,\n",
    "        padding='valid',\n",
    "        data_format='channels_last'\n",
    "    )\n",
    "    self.bn3 = tf.keras.layers.BatchNormalization()\n",
    "    self.conv4 = tf.keras.layers.Conv3D(\n",
    "        filters = 256,\n",
    "        kernel_size = 3,\n",
    "        padding='valid',\n",
    "        data_format='channels_last'\n",
    "    )\n",
    "    self.bn4 = tf.keras.layers.BatchNormalization()\n",
    "    self.fc = {}\n",
    "    for k in list(self.cat_cols.keys()):\n",
    "      self.fc[k] = tf.keras.Sequential([\n",
    "                                        tf.keras.layers.Dense(256, activation='relu'),\n",
    "                                        tf.keras.layers.BatchNormalization(),\n",
    "                                        tf.keras.layers.Dense(self.cat_cols[k], activation='softmax')\n",
    "                                        ])\n",
    "    for i in range(len(self.num_cols)):\n",
    "      self.fc[self.num_cols[i]] = tf.keras.Sequential([\n",
    "                                        tf.keras.layers.Dense(256, activation='relu'),\n",
    "                                        tf.keras.layers.BatchNormalization(),\n",
    "                                        tf.keras.layers.Dense(1)\n",
    "                                        ])\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = self.bn1(x)\n",
    "    x = self.ac(x)\n",
    "    x = self.maxpool(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.bn2(x)\n",
    "    x = self.ac(x)\n",
    "    x = self.maxpool(x)\n",
    "    x = self.conv3(x)\n",
    "    x = self.bn3(x)\n",
    "    x = self.ac(x)\n",
    "    x = self.maxpool(x)\n",
    "    x = self.conv4(x)\n",
    "    x = self.bn4(x)\n",
    "    x = self.ac(x)\n",
    "    x = tf.keras.layers.GlobalAveragePooling3D()(x)\n",
    "    out = {}\n",
    "    for k in list(self.fc.keys()):\n",
    "      out[k] = self.fc[k](x)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q9PZkxi_k5b-"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "\n",
    "class MyDNN(Model):\n",
    "  def __init__(self, cat_cols, num_cols):\n",
    "    super(MyDNN, self).__init__()\n",
    "    self.cat_cols = cat_cols\n",
    "    self.num_cols = num_cols\n",
    "    self.ac = tf.keras.layers.ReLU()\n",
    "    self.maxpool = tf.keras.layers.MaxPool3D(pool_size=(2, 2, 2), data_format='channels_last')\n",
    "    self.conv1 = tf.keras.layers.Conv3D(\n",
    "        filters = 32,\n",
    "        kernel_size = 3,\n",
    "        padding='valid',\n",
    "        data_format='channels_last',\n",
    "        input_shape = (64,64,64,2)\n",
    "    )\n",
    "    self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "    self.conv2 = tf.keras.layers.Conv3D(\n",
    "        filters = 64,\n",
    "        kernel_size = 3,\n",
    "        padding='valid',\n",
    "        data_format='channels_last'\n",
    "    )\n",
    "    self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "    self.conv3 = tf.keras.layers.Conv3D(\n",
    "        filters = 128,\n",
    "        kernel_size = 3,\n",
    "        padding='valid',\n",
    "        data_format='channels_last'\n",
    "    )\n",
    "    self.bn3 = tf.keras.layers.BatchNormalization()\n",
    "    self.conv4 = tf.keras.layers.Conv3D(\n",
    "        filters = 256,\n",
    "        kernel_size = 3,\n",
    "        padding='valid',\n",
    "        data_format='channels_last',\n",
    "        name='lastconv_1'\n",
    "    )\n",
    "    self.bn4 = tf.keras.layers.BatchNormalization()\n",
    "    self.fc = {}\n",
    "    for k in list(self.cat_cols.keys()):\n",
    "      self.fc[k] = tf.keras.Sequential([\n",
    "                                        tf.keras.layers.Dense(256, activation='relu'),\n",
    "                                        tf.keras.layers.BatchNormalization(),\n",
    "                                        tf.keras.layers.Dense(self.cat_cols[k], activation='softmax', name='output_' + k)\n",
    "                                        ])\n",
    "    for i in range(len(self.num_cols)):\n",
    "      self.fc[self.num_cols[i]] = tf.keras.Sequential([\n",
    "                                        tf.keras.layers.Dense(256, activation='relu'),\n",
    "                                        tf.keras.layers.BatchNormalization(),\n",
    "                                        tf.keras.layers.Dense(1)\n",
    "                                        ])\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = self.bn1(x)\n",
    "    x = self.ac(x)\n",
    "    x = self.maxpool(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.bn2(x)\n",
    "    x = self.ac(x)\n",
    "    x = self.maxpool(x)\n",
    "    x = self.conv3(x)\n",
    "    x = self.bn3(x)\n",
    "    x = self.ac(x)\n",
    "    x = self.maxpool(x)\n",
    "    x = self.conv4(x)\n",
    "    x = self.bn4(x)\n",
    "    x = self.ac(x)\n",
    "    x = tf.keras.layers.GlobalAveragePooling3D()(x)\n",
    "    out = {}\n",
    "    for k in list(self.fc.keys()):\n",
    "      out[k] = self.fc[k](x)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tpab_A9TDYeK"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hROMApYiDagm"
   },
   "outputs": [],
   "source": [
    "def calc_loss_acc(out_loss, out_acc, y_true, y_pred, cat_cols, num_cols, norm_dict):\n",
    "  for col in num_cols:\n",
    "    tmp_col = col\n",
    "    tmp_std = norm_dict[tmp_col.replace('_norm','')]['std']\n",
    "    tmp_y_true = tf.cast(y_true[col], tf.float32).numpy()\n",
    "    tmp_y_pred = np.squeeze(y_pred[col].numpy())\n",
    "    if not(tmp_col in out_loss):\n",
    "      out_loss[tmp_col] = np.sum(np.square(tmp_y_true-tmp_y_pred))\n",
    "    else:\n",
    "      out_loss[tmp_col] += np.sum(np.square(tmp_y_true-tmp_y_pred))\n",
    "    if not(tmp_col in out_acc):\n",
    "      out_acc[tmp_col] = np.sum(np.square((tmp_y_true-tmp_y_pred)*tmp_std))\n",
    "    else:\n",
    "      out_acc[tmp_col] += np.sum(np.square((tmp_y_true-tmp_y_pred)*tmp_std))\n",
    "  for col in list(cat_cols.keys()):\n",
    "    tmp_col = col\n",
    "    if not(tmp_col in out_loss):\n",
    "      out_loss[tmp_col] = tf.keras.losses.SparseCategoricalCrossentropy()(tf.squeeze(y_true[col]), tf.squeeze(y_pred[col])).numpy()\n",
    "    else:\n",
    "      out_loss[tmp_col] += tf.keras.losses.SparseCategoricalCrossentropy()(tf.squeeze(y_true[col]), tf.squeeze(y_pred[col])).numpy()\n",
    "    if not(tmp_col in out_acc):\n",
    "      out_acc[tmp_col] = tf.reduce_sum(tf.dtypes.cast((y_true[col] == tf.argmax(y_pred[col], axis=-1)), tf.float32)).numpy()\n",
    "    else:\n",
    "      out_acc[tmp_col] += tf.reduce_sum(tf.dtypes.cast((y_true[col] == tf.argmax(y_pred[col], axis=-1)), tf.float32)).numpy()    \n",
    "  return(out_loss, out_acc)\n",
    "\n",
    "def format_output(out_loss, out_acc, n, cols, print_bl=False):\n",
    "  loss = 0\n",
    "  acc = 0\n",
    "  output = []\n",
    "  for col in cols:\n",
    "    output.append([col, out_loss[col]/n, out_acc[col]/n])\n",
    "    loss += out_loss[col]/n\n",
    "    acc += out_acc[col]/n\n",
    "  df = pd.DataFrame(output)\n",
    "  df.columns = ['name', 'loss', 'acc']\n",
    "  if print_bl:\n",
    "    print(df)\n",
    "  return(loss, acc, df)\n",
    "\n",
    "@tf.function\n",
    "def train_step(X, y, model, optimizer, cat_cols, num_cols):\n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions = model(X)\n",
    "    i = 0\n",
    "    loss = tf.keras.losses.MSE(tf.cast(y[num_cols[i]], tf.float32), tf.squeeze(predictions[num_cols[i]]))\n",
    "    for i in range(1,len(num_cols)):\n",
    "      loss += tf.keras.losses.MSE(tf.cast(y[num_cols[i]], tf.float32), tf.squeeze(predictions[num_cols[i]]))\n",
    "    for col in list(cat_cols.keys()):\n",
    "      loss += tf.keras.losses.SparseCategoricalCrossentropy()(tf.squeeze(y[col]), tf.squeeze(predictions[col]))\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "  return(y, predictions, loss)\n",
    "\n",
    "@tf.function\n",
    "def test_step(X, y, model):\n",
    "  predictions = model(X)\n",
    "  return(y, predictions)\n",
    "\n",
    "def epoch(data_iter, df, model, optimizer, cat_cols, num_cols, norm_dict):\n",
    "  out_loss = {}\n",
    "  out_acc = {}\n",
    "  n = 0.\n",
    "  n_batch = 0.\n",
    "  total_time_dataload = 0.\n",
    "  total_time_model = 0.\n",
    "  start_time = time.time()\n",
    "  for batch in data_iter:\n",
    "    total_time_dataload += time.time() - start_time\n",
    "    start_time = time.time()\n",
    "    t1 = (tf.cast(batch['t1'], tf.float32)-t1_mean)/t1_std\n",
    "    t2 = (batch['t2']-t2_mean)/t2_std\n",
    "    subjectid = decoder(batch['subjectid'])\n",
    "    y = get_labels(df, subjectid, list(cat_cols.keys())+num_cols)\n",
    "    X = tf.concat([t1, t2], axis=4)\n",
    "    if optimizer != None:\n",
    "      y_true, y_pred, loss = train_step(X, y, model, optimizer, cat_cols, num_cols)\n",
    "    else:\n",
    "      y_true, y_pred = test_step(X, y, model)\n",
    "    out_loss, out_acc = calc_loss_acc(out_loss, out_acc, y_true, y_pred, cat_cols, num_cols, norm_dict)\n",
    "    n += X.shape[0]\n",
    "    n_batch += 1\n",
    "    if (n_batch % 10) == 0:\n",
    "      print(n_batch)\n",
    "    total_time_model += time.time() - start_time\n",
    "    start_time = time.time()\n",
    "  return (out_loss, out_acc, n, total_time_model, total_time_dataload)\n",
    "\n",
    "def get_labels(df, subjectid, cols = ['nihtbx_fluidcomp_uncorrected_norm']):\n",
    "  subjects_df = pd.DataFrame(subjectid)\n",
    "  result_df = pd.merge(subjects_df, df, left_on=0, right_on='subjectkey', how='left')\n",
    "  output = {}\n",
    "  for col in cols:\n",
    "    output[col] = np.asarray(result_df[col].values)\n",
    "  return output\n",
    "\n",
    "def best_val(df_best, df_val, df_test):\n",
    "  df_best = pd.merge(df_best, df_val, how='left', left_on='name', right_on='name')\n",
    "  df_best = pd.merge(df_best, df_test, how='left', left_on='name', right_on='name')\n",
    "  df_best.loc[df_best['best_loss_val']>=df_best['cur_loss_val'], 'best_loss_test'] = df_best.loc[df_best['best_loss_val']>=df_best['cur_loss_val'], 'cur_loss_test']\n",
    "  df_best.loc[df_best['best_loss_val']>=df_best['cur_loss_val'], 'best_loss_val'] = df_best.loc[df_best['best_loss_val']>=df_best['cur_loss_val'], 'cur_loss_val']\n",
    "  df_best.loc[(df_best['best_acc_val']<=df_best['cur_acc_val'])&(df_best['name'].isin(['female', 'race.ethnicity', 'high.educ_group', 'income_group', 'married'])), 'best_acc_test'] = df_best.loc[(df_best['best_acc_val']<=df_best['cur_acc_val'])&(df_best['name'].isin(['female', 'race.ethnicity', 'high.educ_group', 'income_group', 'married'])), 'cur_acc_test']\n",
    "  df_best.loc[(df_best['best_acc_val']<=df_best['cur_acc_val'])&(df_best['name'].isin(['female', 'race.ethnicity', 'high.educ_group', 'income_group', 'married'])), 'best_acc_val'] = df_best.loc[(df_best['best_acc_val']<=df_best['cur_acc_val'])&(df_best['name'].isin(['female', 'race.ethnicity', 'high.educ_group', 'income_group', 'married'])), 'cur_acc_val']\n",
    "  df_best.loc[(df_best['best_acc_val']>=df_best['cur_acc_val'])&(~df_best['name'].isin(['female', 'race.ethnicity', 'high.educ_group', 'income_group', 'married'])), 'best_acc_test'] = df_best.loc[(df_best['best_acc_val']>=df_best['cur_acc_val'])&(~df_best['name'].isin(['female', 'race.ethnicity', 'high.educ_group', 'income_group', 'married'])), 'cur_acc_test']\n",
    "  df_best.loc[(df_best['best_acc_val']>=df_best['cur_acc_val'])&(~df_best['name'].isin(['female', 'race.ethnicity', 'high.educ_group', 'income_group', 'married'])), 'best_acc_val'] = df_best.loc[(df_best['best_acc_val']>=df_best['cur_acc_val'])&(~df_best['name'].isin(['female', 'race.ethnicity', 'high.educ_group', 'income_group', 'married'])), 'cur_acc_val']\n",
    "  df_best = df_best.drop(['cur_loss_val', 'cur_acc_val', 'cur_loss_test', 'cur_acc_test'], axis=1)\n",
    "  return(df_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 415,
     "status": "ok",
     "timestamp": 1573636653401,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": -60
    },
    "id": "8iQKsZftjsPR",
    "outputId": "22d8df05-3f92-4c31-d831-e9308b0db4c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'female': 2,\n",
       "  'high.educ_group': 4,\n",
       "  'income_group': 8,\n",
       "  'married': 6,\n",
       "  'race.ethnicity': 5},\n",
       " ['BMI_norm',\n",
       "  'age_norm',\n",
       "  'vol_norm',\n",
       "  'weight_norm',\n",
       "  'height_norm',\n",
       "  'nihtbx_fluidcomp_uncorrected_norm',\n",
       "  'nihtbx_cryst_uncorrected_norm',\n",
       "  'nihtbx_pattern_uncorrected_norm',\n",
       "  'nihtbx_picture_uncorrected_norm',\n",
       "  'nihtbx_list_uncorrected_norm',\n",
       "  'nihtbx_flanker_uncorrected_norm',\n",
       "  'nihtbx_picvocab_uncorrected_norm',\n",
       "  'nihtbx_cardsort_uncorrected_norm',\n",
       "  'nihtbx_totalcomp_uncorrected_norm',\n",
       "  'nihtbx_reading_uncorrected_norm'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols, num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XK13wNFtoIC4"
   },
   "outputs": [],
   "source": [
    "modelname = 'site16_downsample_t1t2_test_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 46355,
     "status": "ok",
     "timestamp": 1573636701683,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": -60
    },
    "id": "RV24LE3k-00n",
    "outputId": "067125be-6ce2-40c9-998e-62f800ccb2f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'female': 2, 'race.ethnicity': 5, 'income_group': 8, 'married': 6, 'high.educ_group': 4}\n",
      "['BMI_norm', 'age_norm', 'vol_norm', 'weight_norm', 'height_norm', 'nihtbx_fluidcomp_uncorrected_norm', 'nihtbx_cryst_uncorrected_norm', 'nihtbx_pattern_uncorrected_norm', 'nihtbx_picture_uncorrected_norm', 'nihtbx_list_uncorrected_norm', 'nihtbx_flanker_uncorrected_norm', 'nihtbx_picvocab_uncorrected_norm', 'nihtbx_cardsort_uncorrected_norm', 'nihtbx_totalcomp_uncorrected_norm', 'nihtbx_reading_uncorrected_norm']\n",
      "Epochs: 0\n",
      "10.0\n",
      "20.0\n",
      "30.0\n",
      "40.0\n",
      "50.0\n",
      "60.0\n",
      "70.0\n",
      "10.0\n",
      "10.0\n",
      "                                 name  best_loss_test  best_acc_test\n",
      "0                              female        0.090675       0.508197\n",
      "1                      race.ethnicity        0.091352       0.778689\n",
      "2                        income_group        0.247845       0.245902\n",
      "3                             married        0.079333       0.860656\n",
      "4                     high.educ_group        0.046390       0.926230\n",
      "5                            BMI_norm        0.857164      15.070319\n",
      "6                            age_norm        1.190903      66.616019\n",
      "7                            vol_norm        0.617604       0.619705\n",
      "8                         weight_norm        1.025919     558.006148\n",
      "9                         height_norm        0.846331       8.412420\n",
      "10  nihtbx_fluidcomp_uncorrected_norm        0.770617       0.578010\n",
      "11      nihtbx_cryst_uncorrected_norm        1.013033       0.623520\n",
      "12    nihtbx_pattern_uncorrected_norm        0.741226       0.667073\n",
      "13    nihtbx_picture_uncorrected_norm        0.753861       0.691576\n",
      "14       nihtbx_list_uncorrected_norm        0.796692       0.630854\n",
      "15    nihtbx_flanker_uncorrected_norm        0.796702       0.655539\n",
      "16   nihtbx_picvocab_uncorrected_norm        1.094452       0.707202\n",
      "17   nihtbx_cardsort_uncorrected_norm        0.731622       0.628849\n",
      "18  nihtbx_totalcomp_uncorrected_norm        0.876128       0.542190\n",
      "19    nihtbx_reading_uncorrected_norm        0.806791       0.592921\n",
      "                                 name  best_loss_val  best_acc_val\n",
      "0                              female       0.084770      0.459016\n",
      "1                      race.ethnicity       0.072450      0.786885\n",
      "2                        income_group       0.216342      0.360656\n",
      "3                             married       0.070375      0.819672\n",
      "4                     high.educ_group       0.053211      0.836066\n",
      "5                            BMI_norm       0.676837     11.899880\n",
      "6                            age_norm       1.305456     73.023782\n",
      "7                            vol_norm       0.763591      0.766189\n",
      "8                         weight_norm       0.740780    402.916464\n",
      "9                         height_norm       0.784366      7.796497\n",
      "10  nihtbx_fluidcomp_uncorrected_norm       0.924374      0.693338\n",
      "11      nihtbx_cryst_uncorrected_norm       0.947528      0.583202\n",
      "12    nihtbx_pattern_uncorrected_norm       0.883631      0.795232\n",
      "13    nihtbx_picture_uncorrected_norm       1.016658      0.932660\n",
      "14       nihtbx_list_uncorrected_norm       0.762352      0.603663\n",
      "15    nihtbx_flanker_uncorrected_norm       0.953348      0.784429\n",
      "16   nihtbx_picvocab_uncorrected_norm       0.987209      0.637904\n",
      "17   nihtbx_cardsort_uncorrected_norm       0.814661      0.700223\n",
      "18  nihtbx_totalcomp_uncorrected_norm       0.847165      0.524266\n",
      "19    nihtbx_reading_uncorrected_norm       0.826567      0.607455\n",
      "Epoch 0, Loss: 1051.683, Accuracy: 13638.878, Val Loss: 13.732, Val Accuracy: 506.527, Time Model: 31.993, Time Data: 2.344\n",
      "Epochs: 1\n",
      "10.0\n",
      "20.0\n",
      "30.0\n",
      "40.0\n",
      "50.0\n",
      "60.0\n",
      "70.0\n",
      "10.0\n",
      "10.0\n",
      "                                 name  best_loss_test  best_acc_test\n",
      "0                              female        0.088393       0.549180\n",
      "1                      race.ethnicity        0.090531       0.778689\n",
      "2                        income_group        0.247845       0.245902\n",
      "3                             married        0.079333       0.860656\n",
      "4                     high.educ_group        0.046390       0.926230\n",
      "5                            BMI_norm        0.702896      12.358042\n",
      "6                            age_norm        1.190903      66.616019\n",
      "7                            vol_norm        0.477972       0.479598\n",
      "8                         weight_norm        0.876674     476.830334\n",
      "9                         height_norm        0.892654       8.872872\n",
      "10  nihtbx_fluidcomp_uncorrected_norm        0.770617       0.578010\n",
      "11      nihtbx_cryst_uncorrected_norm        1.013033       0.623520\n",
      "12    nihtbx_pattern_uncorrected_norm        0.741226       0.667073\n",
      "13    nihtbx_picture_uncorrected_norm        0.757380       0.694804\n",
      "14       nihtbx_list_uncorrected_norm        0.796692       0.630854\n",
      "15    nihtbx_flanker_uncorrected_norm        0.796702       0.655539\n",
      "16   nihtbx_picvocab_uncorrected_norm        1.094452       0.707202\n",
      "17   nihtbx_cardsort_uncorrected_norm        0.731622       0.628849\n",
      "18  nihtbx_totalcomp_uncorrected_norm        0.876128       0.542190\n",
      "19    nihtbx_reading_uncorrected_norm        0.806791       0.592921\n",
      "                                 name  best_loss_val  best_acc_val\n",
      "0                              female       0.082354      0.540984\n",
      "1                      race.ethnicity       0.069650      0.786885\n",
      "2                        income_group       0.216342      0.360656\n",
      "3                             married       0.070375      0.819672\n",
      "4                     high.educ_group       0.053211      0.836066\n",
      "5                            BMI_norm       0.470423      8.270801\n",
      "6                            age_norm       1.305456     73.023782\n",
      "7                            vol_norm       0.577195      0.579159\n",
      "8                         weight_norm       0.534579    290.761975\n",
      "9                         height_norm       0.734020      7.296063\n",
      "10  nihtbx_fluidcomp_uncorrected_norm       0.924374      0.693338\n",
      "11      nihtbx_cryst_uncorrected_norm       0.947528      0.583202\n",
      "12    nihtbx_pattern_uncorrected_norm       0.883631      0.795232\n",
      "13    nihtbx_picture_uncorrected_norm       1.016169      0.932212\n",
      "14       nihtbx_list_uncorrected_norm       0.762352      0.603663\n",
      "15    nihtbx_flanker_uncorrected_norm       0.953348      0.784429\n",
      "16   nihtbx_picvocab_uncorrected_norm       0.987209      0.637904\n",
      "17   nihtbx_cardsort_uncorrected_norm       0.814661      0.700223\n",
      "18  nihtbx_totalcomp_uncorrected_norm       0.847165      0.524266\n",
      "19    nihtbx_reading_uncorrected_norm       0.826567      0.607455\n",
      "Epoch 1, Loss: 64.670, Accuracy: 1713.961, Val Loss: 13.462, Val Accuracy: 391.433, Time Model: 20.823, Time Data: 2.381\n",
      "Epochs: 2\n",
      "10.0\n",
      "20.0\n",
      "30.0\n",
      "40.0\n",
      "50.0\n",
      "60.0\n",
      "70.0\n",
      "10.0\n",
      "10.0\n",
      "                                 name  best_loss_test  best_acc_test\n",
      "0                              female        0.082861       0.622951\n",
      "1                      race.ethnicity        0.089192       0.778689\n",
      "2                        income_group        0.247845       0.245902\n",
      "3                             married        0.079333       0.860656\n",
      "4                     high.educ_group        0.046390       0.926230\n",
      "5                            BMI_norm        0.462464       8.130863\n",
      "6                            age_norm        1.221403      68.322098\n",
      "7                            vol_norm        0.413432       0.414839\n",
      "8                         weight_norm        0.599270     325.947938\n",
      "9                         height_norm        0.783563       7.788520\n",
      "10  nihtbx_fluidcomp_uncorrected_norm        0.770617       0.578010\n",
      "11      nihtbx_cryst_uncorrected_norm        1.013033       0.623520\n",
      "12    nihtbx_pattern_uncorrected_norm        0.741226       0.667073\n",
      "13    nihtbx_picture_uncorrected_norm        0.758811       0.696117\n",
      "14       nihtbx_list_uncorrected_norm        0.796692       0.630854\n",
      "15    nihtbx_flanker_uncorrected_norm        0.796702       0.655539\n",
      "16   nihtbx_picvocab_uncorrected_norm        1.094452       0.707202\n",
      "17   nihtbx_cardsort_uncorrected_norm        0.731622       0.628849\n",
      "18  nihtbx_totalcomp_uncorrected_norm        0.876128       0.542190\n",
      "19    nihtbx_reading_uncorrected_norm        0.806791       0.592921\n",
      "                                 name  best_loss_val  best_acc_val\n",
      "0                              female       0.078373      0.565574\n",
      "1                      race.ethnicity       0.069255      0.786885\n",
      "2                        income_group       0.216342      0.360656\n",
      "3                             married       0.070375      0.819672\n",
      "4                     high.educ_group       0.053211      0.836066\n",
      "5                            BMI_norm       0.293673      5.163237\n",
      "6                            age_norm       1.292683     72.309306\n",
      "7                            vol_norm       0.390735      0.392065\n",
      "8                         weight_norm       0.322962    175.661885\n",
      "9                         height_norm       0.589577      5.860316\n",
      "10  nihtbx_fluidcomp_uncorrected_norm       0.924374      0.693338\n",
      "11      nihtbx_cryst_uncorrected_norm       0.947528      0.583202\n",
      "12    nihtbx_pattern_uncorrected_norm       0.883631      0.795232\n",
      "13    nihtbx_picture_uncorrected_norm       1.012874      0.929190\n",
      "14       nihtbx_list_uncorrected_norm       0.762352      0.603663\n",
      "15    nihtbx_flanker_uncorrected_norm       0.953348      0.784429\n",
      "16   nihtbx_picvocab_uncorrected_norm       0.987209      0.637904\n",
      "17   nihtbx_cardsort_uncorrected_norm       0.814661      0.700223\n",
      "18  nihtbx_totalcomp_uncorrected_norm       0.847165      0.524266\n",
      "19    nihtbx_reading_uncorrected_norm       0.826567      0.607455\n",
      "Epoch 2, Loss: 62.216, Accuracy: 1357.944, Val Loss: 12.699, Val Accuracy: 269.874, Time Model: 20.743, Time Data: 2.413\n",
      "Epochs: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n",
      "20.0\n",
      "30.0\n",
      "40.0\n",
      "50.0\n",
      "60.0\n",
      "70.0\n",
      "10.0\n",
      "10.0\n",
      "                                 name  best_loss_test  best_acc_test\n",
      "0                              female        0.080367       0.672131\n",
      "1                      race.ethnicity        0.089507       0.778689\n",
      "2                        income_group        0.247845       0.245902\n",
      "3                             married        0.079333       0.860656\n",
      "4                     high.educ_group        0.046390       0.926230\n",
      "5                            BMI_norm        0.356292       6.264189\n",
      "6                            age_norm        1.205179      67.414543\n",
      "7                            vol_norm        0.400940       0.402304\n",
      "8                         weight_norm        0.451367     245.502561\n",
      "9                         height_norm        0.706129       7.018833\n",
      "10  nihtbx_fluidcomp_uncorrected_norm        0.770617       0.578010\n",
      "11      nihtbx_cryst_uncorrected_norm        1.013033       0.623520\n",
      "12    nihtbx_pattern_uncorrected_norm        0.741226       0.667073\n",
      "13    nihtbx_picture_uncorrected_norm        0.763160       0.700106\n",
      "14       nihtbx_list_uncorrected_norm        0.796692       0.630854\n",
      "15    nihtbx_flanker_uncorrected_norm        0.796702       0.655539\n",
      "16   nihtbx_picvocab_uncorrected_norm        1.094452       0.707202\n",
      "17   nihtbx_cardsort_uncorrected_norm        0.731622       0.628849\n",
      "18  nihtbx_totalcomp_uncorrected_norm        0.876128       0.542190\n",
      "19    nihtbx_reading_uncorrected_norm        0.806791       0.592921\n",
      "                                 name  best_loss_val  best_acc_val\n",
      "0                              female       0.076970      0.573770\n",
      "1                      race.ethnicity       0.069179      0.786885\n",
      "2                        income_group       0.216342      0.360656\n",
      "3                             married       0.070375      0.819672\n",
      "4                     high.educ_group       0.053211      0.836066\n",
      "5                            BMI_norm       0.228529      4.017906\n",
      "6                            age_norm       1.256460     70.283059\n",
      "7                            vol_norm       0.340733      0.341893\n",
      "8                         weight_norm       0.232123    126.253650\n",
      "9                         height_norm       0.522155      5.190152\n",
      "10  nihtbx_fluidcomp_uncorrected_norm       0.924374      0.693338\n",
      "11      nihtbx_cryst_uncorrected_norm       0.947528      0.583202\n",
      "12    nihtbx_pattern_uncorrected_norm       0.883631      0.795232\n",
      "13    nihtbx_picture_uncorrected_norm       1.010687      0.927183\n",
      "14       nihtbx_list_uncorrected_norm       0.762352      0.603663\n",
      "15    nihtbx_flanker_uncorrected_norm       0.953348      0.784429\n",
      "16   nihtbx_picvocab_uncorrected_norm       0.987209      0.637904\n",
      "17   nihtbx_cardsort_uncorrected_norm       0.814661      0.700223\n",
      "18  nihtbx_totalcomp_uncorrected_norm       0.847165      0.524266\n",
      "19    nihtbx_reading_uncorrected_norm       0.826567      0.607455\n",
      "Epoch 3, Loss: 60.637, Accuracy: 1158.834, Val Loss: 12.349, Val Accuracy: 216.548, Time Model: 20.804, Time Data: 2.375\n",
      "Epochs: 4\n",
      "10.0\n",
      "20.0\n",
      "30.0\n",
      "40.0\n",
      "50.0\n",
      "60.0\n",
      "70.0\n",
      "10.0\n",
      "10.0\n",
      "                                 name  best_loss_test  best_acc_test\n",
      "0                              female        0.077233       0.680328\n",
      "1                      race.ethnicity        0.088079       0.778689\n",
      "2                        income_group        0.247845       0.245902\n",
      "3                             married        0.079333       0.860656\n",
      "4                     high.educ_group        0.046390       0.926230\n",
      "5                            BMI_norm        0.268643       4.723183\n",
      "6                            age_norm        1.177524      65.867584\n",
      "7                            vol_norm        0.289675       0.290661\n",
      "8                         weight_norm        0.339868     184.857246\n",
      "9                         height_norm        0.654858       6.509202\n",
      "10  nihtbx_fluidcomp_uncorrected_norm        0.770617       0.578010\n",
      "11      nihtbx_cryst_uncorrected_norm        1.013033       0.623520\n",
      "12    nihtbx_pattern_uncorrected_norm        0.741226       0.667073\n",
      "13    nihtbx_picture_uncorrected_norm        0.764555       0.701386\n",
      "14       nihtbx_list_uncorrected_norm        0.796692       0.630854\n",
      "15    nihtbx_flanker_uncorrected_norm        0.796702       0.655539\n",
      "16   nihtbx_picvocab_uncorrected_norm        1.094452       0.707202\n",
      "17   nihtbx_cardsort_uncorrected_norm        0.731622       0.628849\n",
      "18  nihtbx_totalcomp_uncorrected_norm        0.876128       0.542190\n",
      "19    nihtbx_reading_uncorrected_norm        0.806791       0.592921\n",
      "                                 name  best_loss_val  best_acc_val\n",
      "0                              female       0.074870      0.598361\n",
      "1                      race.ethnicity       0.068625      0.786885\n",
      "2                        income_group       0.216342      0.360656\n",
      "3                             married       0.070375      0.819672\n",
      "4                     high.educ_group       0.053211      0.836066\n",
      "5                            BMI_norm       0.175313      3.082288\n",
      "6                            age_norm       1.223547     68.442023\n",
      "7                            vol_norm       0.238628      0.239440\n",
      "8                         weight_norm       0.172071     93.590844\n",
      "9                         height_norm       0.490601      4.876514\n",
      "10  nihtbx_fluidcomp_uncorrected_norm       0.924374      0.693338\n",
      "11      nihtbx_cryst_uncorrected_norm       0.947528      0.583202\n",
      "12    nihtbx_pattern_uncorrected_norm       0.883631      0.795232\n",
      "13    nihtbx_picture_uncorrected_norm       1.004229      0.921258\n",
      "14       nihtbx_list_uncorrected_norm       0.762352      0.603663\n",
      "15    nihtbx_flanker_uncorrected_norm       0.953348      0.784429\n",
      "16   nihtbx_picvocab_uncorrected_norm       0.987209      0.637904\n",
      "17   nihtbx_cardsort_uncorrected_norm       0.814661      0.700223\n",
      "18  nihtbx_totalcomp_uncorrected_norm       0.847165      0.524266\n",
      "19    nihtbx_reading_uncorrected_norm       0.826567      0.607455\n",
      "Epoch 4, Loss: 59.421, Accuracy: 1034.104, Val Loss: 11.997, Val Accuracy: 180.674, Time Model: 20.732, Time Data: 2.339\n",
      "Epochs: 5\n",
      "10.0\n",
      "20.0\n",
      "30.0\n",
      "40.0\n",
      "50.0\n",
      "60.0\n",
      "70.0\n",
      "10.0\n",
      "10.0\n",
      "                                 name  best_loss_test  best_acc_test\n",
      "0                              female        0.075957       0.721311\n",
      "1                      race.ethnicity        0.086152       0.778689\n",
      "2                        income_group        0.247845       0.245902\n",
      "3                             married        0.080558       0.860656\n",
      "4                     high.educ_group        0.044210       0.926230\n",
      "5                            BMI_norm        0.268643       4.723183\n",
      "6                            age_norm        1.177524      65.867584\n",
      "7                            vol_norm        0.224361       0.225124\n",
      "8                         weight_norm        0.339868     184.857246\n",
      "9                         height_norm        0.645699       6.418168\n",
      "10  nihtbx_fluidcomp_uncorrected_norm        0.770617       0.578010\n",
      "11      nihtbx_cryst_uncorrected_norm        1.013033       0.623520\n",
      "12    nihtbx_pattern_uncorrected_norm        0.741226       0.667073\n",
      "13    nihtbx_picture_uncorrected_norm        0.761921       0.698970\n",
      "14       nihtbx_list_uncorrected_norm        0.796692       0.630854\n",
      "15    nihtbx_flanker_uncorrected_norm        0.796702       0.655539\n",
      "16   nihtbx_picvocab_uncorrected_norm        1.072040       0.692720\n",
      "17   nihtbx_cardsort_uncorrected_norm        0.731622       0.628849\n",
      "18  nihtbx_totalcomp_uncorrected_norm        0.876128       0.542190\n",
      "19    nihtbx_reading_uncorrected_norm        0.806791       0.592921\n",
      "                                 name  best_loss_val  best_acc_val\n",
      "0                              female       0.073239      0.639344\n",
      "1                      race.ethnicity       0.068023      0.786885\n",
      "2                        income_group       0.216342      0.360656\n",
      "3                             married       0.070364      0.819672\n",
      "4                     high.educ_group       0.050660      0.836066\n",
      "5                            BMI_norm       0.175313      3.082288\n",
      "6                            age_norm       1.223547     68.442023\n",
      "7                            vol_norm       0.195036      0.195700\n",
      "8                         weight_norm       0.172071     93.590844\n",
      "9                         height_norm       0.482809      4.799062\n",
      "10  nihtbx_fluidcomp_uncorrected_norm       0.924374      0.693338\n",
      "11      nihtbx_cryst_uncorrected_norm       0.947528      0.583202\n",
      "12    nihtbx_pattern_uncorrected_norm       0.883631      0.795232\n",
      "13    nihtbx_picture_uncorrected_norm       1.001774      0.919006\n",
      "14       nihtbx_list_uncorrected_norm       0.762352      0.603663\n",
      "15    nihtbx_flanker_uncorrected_norm       0.953348      0.784429\n",
      "16   nihtbx_picvocab_uncorrected_norm       0.981476      0.634200\n",
      "17   nihtbx_cardsort_uncorrected_norm       0.814661      0.700223\n",
      "18  nihtbx_totalcomp_uncorrected_norm       0.847165      0.524266\n",
      "19    nihtbx_reading_uncorrected_norm       0.826567      0.607455\n",
      "Epoch 5, Loss: 58.384, Accuracy: 938.181, Val Loss: 11.858, Val Accuracy: 181.708, Time Model: 20.809, Time Data: 2.390\n",
      "Epochs: 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n",
      "20.0\n",
      "30.0\n",
      "40.0\n",
      "50.0\n",
      "60.0\n",
      "70.0\n",
      "10.0\n",
      "10.0\n",
      "                                 name  best_loss_test  best_acc_test\n",
      "0                              female        0.072749       0.721311\n",
      "1                      race.ethnicity        0.085731       0.778689\n",
      "2                        income_group        0.247845       0.245902\n",
      "3                             married        0.080558       0.860656\n",
      "4                     high.educ_group        0.043531       0.926230\n",
      "5                            BMI_norm        0.226856       3.988500\n",
      "6                            age_norm        1.173895      65.664631\n",
      "7                            vol_norm        0.185348       0.185979\n",
      "8                         weight_norm        0.293041     159.387583\n",
      "9                         height_norm        0.636488       6.326605\n",
      "10  nihtbx_fluidcomp_uncorrected_norm        0.770617       0.578010\n",
      "11      nihtbx_cryst_uncorrected_norm        1.013033       0.623520\n",
      "12    nihtbx_pattern_uncorrected_norm        0.732462       0.659186\n",
      "13    nihtbx_picture_uncorrected_norm        0.761629       0.698702\n",
      "14       nihtbx_list_uncorrected_norm        0.796692       0.630854\n",
      "15    nihtbx_flanker_uncorrected_norm        0.796702       0.655539\n",
      "16   nihtbx_picvocab_uncorrected_norm        1.073806       0.693860\n",
      "17   nihtbx_cardsort_uncorrected_norm        0.731622       0.628849\n",
      "18  nihtbx_totalcomp_uncorrected_norm        0.876128       0.542190\n",
      "19    nihtbx_reading_uncorrected_norm        0.806791       0.592921\n",
      "                                 name  best_loss_val  best_acc_val\n",
      "0                              female       0.070890      0.663934\n",
      "1                      race.ethnicity       0.067390      0.786885\n",
      "2                        income_group       0.216342      0.360656\n",
      "3                             married       0.070364      0.819672\n",
      "4                     high.educ_group       0.049095      0.836066\n",
      "5                            BMI_norm       0.168103      2.955526\n",
      "6                            age_norm       1.213348     67.871518\n",
      "7                            vol_norm       0.161435      0.161984\n",
      "8                         weight_norm       0.167101     90.887407\n",
      "9                         height_norm       0.474909      4.720536\n",
      "10  nihtbx_fluidcomp_uncorrected_norm       0.924374      0.693338\n",
      "11      nihtbx_cryst_uncorrected_norm       0.947528      0.583202\n",
      "12    nihtbx_pattern_uncorrected_norm       0.875696      0.788091\n",
      "13    nihtbx_picture_uncorrected_norm       0.998225      0.915751\n",
      "14       nihtbx_list_uncorrected_norm       0.762352      0.603663\n",
      "15    nihtbx_flanker_uncorrected_norm       0.953348      0.784429\n",
      "16   nihtbx_picvocab_uncorrected_norm       0.974934      0.629972\n",
      "17   nihtbx_cardsort_uncorrected_norm       0.814661      0.700223\n",
      "18  nihtbx_totalcomp_uncorrected_norm       0.847165      0.524266\n",
      "19    nihtbx_reading_uncorrected_norm       0.826567      0.607455\n",
      "Epoch 6, Loss: 57.749, Accuracy: 859.167, Val Loss: 11.745, Val Accuracy: 177.017, Time Model: 20.755, Time Data: 2.385\n",
      "Epochs: 7\n",
      "10.0\n",
      "20.0\n",
      "30.0\n",
      "40.0\n",
      "50.0\n",
      "60.0\n",
      "70.0\n",
      "10.0\n",
      "10.0\n",
      "                                 name  best_loss_test  best_acc_test\n",
      "0                              female        0.072364       0.713115\n",
      "1                      race.ethnicity        0.085053       0.778689\n",
      "2                        income_group        0.247845       0.245902\n",
      "3                             married        0.080558       0.860656\n",
      "4                     high.educ_group        0.043441       0.926230\n",
      "5                            BMI_norm        0.214943       3.779046\n",
      "6                            age_norm        1.173895      65.664631\n",
      "7                            vol_norm        0.166172       0.166737\n",
      "8                         weight_norm        0.274406     149.251633\n",
      "9                         height_norm        0.636488       6.326605\n",
      "10  nihtbx_fluidcomp_uncorrected_norm        0.770617       0.578010\n",
      "11      nihtbx_cryst_uncorrected_norm        1.013033       0.623520\n",
      "12    nihtbx_pattern_uncorrected_norm        0.729235       0.656282\n",
      "13    nihtbx_picture_uncorrected_norm        0.762203       0.699229\n",
      "14       nihtbx_list_uncorrected_norm        0.796692       0.630854\n",
      "15    nihtbx_flanker_uncorrected_norm        0.796702       0.655539\n",
      "16   nihtbx_picvocab_uncorrected_norm        1.073806       0.693860\n",
      "17   nihtbx_cardsort_uncorrected_norm        0.731622       0.628849\n",
      "18  nihtbx_totalcomp_uncorrected_norm        0.876128       0.542190\n",
      "19    nihtbx_reading_uncorrected_norm        0.806791       0.592921\n",
      "                                 name  best_loss_val  best_acc_val\n",
      "0                              female       0.070140      0.680328\n",
      "1                      race.ethnicity       0.066781      0.786885\n",
      "2                        income_group       0.216342      0.360656\n",
      "3                             married       0.070364      0.819672\n",
      "4                     high.educ_group       0.048455      0.836066\n",
      "5                            BMI_norm       0.153291      2.695101\n",
      "6                            age_norm       1.213348     67.871518\n",
      "7                            vol_norm       0.160110      0.160655\n",
      "8                         weight_norm       0.153078     83.260286\n",
      "9                         height_norm       0.474909      4.720536\n",
      "10  nihtbx_fluidcomp_uncorrected_norm       0.924374      0.693338\n",
      "11      nihtbx_cryst_uncorrected_norm       0.947528      0.583202\n",
      "12    nihtbx_pattern_uncorrected_norm       0.869854      0.782833\n",
      "13    nihtbx_picture_uncorrected_norm       0.997478      0.915065\n",
      "14       nihtbx_list_uncorrected_norm       0.762352      0.603663\n",
      "15    nihtbx_flanker_uncorrected_norm       0.953348      0.784429\n",
      "16   nihtbx_picvocab_uncorrected_norm       0.974934      0.629972\n",
      "17   nihtbx_cardsort_uncorrected_norm       0.814661      0.700223\n",
      "18  nihtbx_totalcomp_uncorrected_norm       0.847165      0.524266\n",
      "19    nihtbx_reading_uncorrected_norm       0.826567      0.607455\n",
      "Epoch 7, Loss: 57.113, Accuracy: 791.979, Val Loss: 11.794, Val Accuracy: 170.857, Time Model: 20.776, Time Data: 2.373\n",
      "Epochs: 8\n",
      "10.0\n",
      "20.0\n",
      "30.0\n",
      "40.0\n",
      "50.0\n",
      "60.0\n",
      "70.0\n",
      "10.0\n",
      "10.0\n",
      "                                 name  best_loss_test  best_acc_test\n",
      "0                              female        0.070375       0.762295\n",
      "1                      race.ethnicity        0.084930       0.778689\n",
      "2                        income_group        0.244081       0.245902\n",
      "3                             married        0.080558       0.860656\n",
      "4                     high.educ_group        0.043824       0.926230\n",
      "5                            BMI_norm        0.198922       3.497361\n",
      "6                            age_norm        1.173895      65.664631\n",
      "7                            vol_norm        0.166172       0.166737\n",
      "8                         weight_norm        0.263671     143.412942\n",
      "9                         height_norm        0.636488       6.326605\n",
      "10  nihtbx_fluidcomp_uncorrected_norm        0.770617       0.578010\n",
      "11      nihtbx_cryst_uncorrected_norm        1.013033       0.623520\n",
      "12    nihtbx_pattern_uncorrected_norm        0.729235       0.656282\n",
      "13    nihtbx_picture_uncorrected_norm        0.763574       0.700486\n",
      "14       nihtbx_list_uncorrected_norm        0.796692       0.630854\n",
      "15    nihtbx_flanker_uncorrected_norm        0.810091       0.666556\n",
      "16   nihtbx_picvocab_uncorrected_norm        1.078292       0.696759\n",
      "17   nihtbx_cardsort_uncorrected_norm        0.731622       0.628849\n",
      "18  nihtbx_totalcomp_uncorrected_norm        0.876128       0.542190\n",
      "19    nihtbx_reading_uncorrected_norm        0.806791       0.592921\n",
      "                                 name  best_loss_val  best_acc_val\n",
      "0                              female       0.068444      0.713115\n",
      "1                      race.ethnicity       0.065778      0.786885\n",
      "2                        income_group       0.215987      0.360656\n",
      "3                             married       0.070364      0.819672\n",
      "4                     high.educ_group       0.048106      0.836066\n",
      "5                            BMI_norm       0.146370      2.573429\n",
      "6                            age_norm       1.213348     67.871518\n",
      "7                            vol_norm       0.160110      0.160655\n",
      "8                         weight_norm       0.148975     81.028969\n",
      "9                         height_norm       0.474909      4.720536\n",
      "10  nihtbx_fluidcomp_uncorrected_norm       0.924374      0.693338\n",
      "11      nihtbx_cryst_uncorrected_norm       0.947528      0.583202\n",
      "12    nihtbx_pattern_uncorrected_norm       0.869854      0.782833\n",
      "13    nihtbx_picture_uncorrected_norm       0.992110      0.910141\n",
      "14       nihtbx_list_uncorrected_norm       0.762352      0.603663\n",
      "15    nihtbx_flanker_uncorrected_norm       0.949066      0.780906\n",
      "16   nihtbx_picvocab_uncorrected_norm       0.972820      0.628606\n",
      "17   nihtbx_cardsort_uncorrected_norm       0.814661      0.700223\n",
      "18  nihtbx_totalcomp_uncorrected_norm       0.847165      0.524266\n",
      "19    nihtbx_reading_uncorrected_norm       0.826567      0.607455\n",
      "Epoch 8, Loss: 56.941, Accuracy: 767.932, Val Loss: 11.811, Val Accuracy: 169.705, Time Model: 20.831, Time Data: 2.377\n",
      "Epochs: 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n",
      "20.0\n",
      "30.0\n",
      "40.0\n",
      "50.0\n",
      "60.0\n",
      "70.0\n",
      "10.0\n",
      "10.0\n",
      "                                 name  best_loss_test  best_acc_test\n",
      "0                              female        0.066124       0.803279\n",
      "1                      race.ethnicity        0.084216       0.778689\n",
      "2                        income_group        0.243653       0.245902\n",
      "3                             married        0.080558       0.860656\n",
      "4                     high.educ_group        0.043824       0.926230\n",
      "5                            BMI_norm        0.190272       3.345294\n",
      "6                            age_norm        1.173895      65.664631\n",
      "7                            vol_norm        0.166172       0.166737\n",
      "8                         weight_norm        0.260217     141.534180\n",
      "9                         height_norm        0.636488       6.326605\n",
      "10  nihtbx_fluidcomp_uncorrected_norm        0.770617       0.578010\n",
      "11      nihtbx_cryst_uncorrected_norm        1.013033       0.623520\n",
      "12    nihtbx_pattern_uncorrected_norm        0.729235       0.656282\n",
      "13    nihtbx_picture_uncorrected_norm        0.761753       0.698816\n",
      "14       nihtbx_list_uncorrected_norm        0.796692       0.630854\n",
      "15    nihtbx_flanker_uncorrected_norm        0.810091       0.666556\n",
      "16   nihtbx_picvocab_uncorrected_norm        1.078292       0.696759\n",
      "17   nihtbx_cardsort_uncorrected_norm        0.731622       0.628849\n",
      "18  nihtbx_totalcomp_uncorrected_norm        0.876128       0.542190\n",
      "19    nihtbx_reading_uncorrected_norm        0.806791       0.592921\n",
      "                                 name  best_loss_val  best_acc_val\n",
      "0                              female       0.065377      0.737705\n",
      "1                      race.ethnicity       0.064617      0.786885\n",
      "2                        income_group       0.215495      0.360656\n",
      "3                             married       0.070364      0.819672\n",
      "4                     high.educ_group       0.048106      0.836066\n",
      "5                            BMI_norm       0.142792      2.510507\n",
      "6                            age_norm       1.213348     67.871518\n",
      "7                            vol_norm       0.160110      0.160655\n",
      "8                         weight_norm       0.144134     78.395708\n",
      "9                         height_norm       0.474909      4.720536\n",
      "10  nihtbx_fluidcomp_uncorrected_norm       0.924374      0.693338\n",
      "11      nihtbx_cryst_uncorrected_norm       0.947528      0.583202\n",
      "12    nihtbx_pattern_uncorrected_norm       0.869854      0.782833\n",
      "13    nihtbx_picture_uncorrected_norm       0.989367      0.907624\n",
      "14       nihtbx_list_uncorrected_norm       0.762352      0.603663\n",
      "15    nihtbx_flanker_uncorrected_norm       0.949066      0.780906\n",
      "16   nihtbx_picvocab_uncorrected_norm       0.972820      0.628606\n",
      "17   nihtbx_cardsort_uncorrected_norm       0.814661      0.700223\n",
      "18  nihtbx_totalcomp_uncorrected_norm       0.847165      0.524266\n",
      "19    nihtbx_reading_uncorrected_norm       0.826567      0.607455\n",
      "Epoch 9, Loss: 56.633, Accuracy: 745.238, Val Loss: 11.803, Val Accuracy: 166.681, Time Model: 20.752, Time Data: 2.349\n"
     ]
    }
   ],
   "source": [
    "decoder = np.vectorize(lambda x: x.decode('UTF-8'))\n",
    "template = 'Epoch {0}, Loss: {1:.3f}, Accuracy: {2:.3f}, Val Loss: {3:.3f}, Val Accuracy: {4:.3f}, Time Model: {5:.3f}, Time Data: {6:.3f}'\n",
    "for col in [0]:\n",
    "  log_textfile(path_output + modelname + 'multitask_test' + '.log', cat_cols),\n",
    "  log_textfile(path_output + modelname + 'multitask_test' + '.log', num_cols)\n",
    "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "  optimizer = tf.keras.optimizers.Adam(lr = 0.001)\n",
    "  model = MyDNN(cat_cols, num_cols)\n",
    "  df_best = None\n",
    "  for e in range(10):\n",
    "    log_textfile(path_output + modelname + 'multitask_test' + '.log', 'Epochs: ' + str(e))\n",
    "    loss = tf.Variable(0.)\n",
    "    acc = tf.Variable(0.) \n",
    "    val_loss = tf.Variable(0.)\n",
    "    val_acc = tf.Variable(0.)\n",
    "    test_loss = tf.Variable(0.)\n",
    "    test_acc = tf.Variable(0.)  \n",
    "    train_out_loss, train_out_acc, n, time_model, time_data = epoch(train_iter, train_df, model, optimizer, cat_cols, num_cols, norm_dict)\n",
    "    val_out_loss, val_out_acc, n, _, _ = epoch(val_iter, val_df, model, None, cat_cols, num_cols, norm_dict)\n",
    "    test_out_loss, test_out_acc, n, _, _ = epoch(test_iter, test_df, model, None, cat_cols, num_cols, norm_dict)\n",
    "    loss, acc, _ = format_output(train_out_loss, train_out_acc, n, list(cat_cols.keys())+num_cols)\n",
    "    val_loss, val_acc, df_val = format_output(val_out_loss, val_out_acc, n, list(cat_cols.keys())+num_cols, print_bl=False)\n",
    "    test_loss, test_acc, df_test = format_output(test_out_loss, test_out_acc, n, list(cat_cols.keys())+num_cols, print_bl=False)\n",
    "    df_val.columns = ['name', 'cur_loss_val', 'cur_acc_val']\n",
    "    df_test.columns = ['name', 'cur_loss_test', 'cur_acc_test']\n",
    "    if e == 0:\n",
    "      df_best = pd.merge(df_test, df_val, how='left', left_on='name', right_on='name')\n",
    "      df_best.columns = ['name', 'best_loss_test', 'best_acc_test', 'best_loss_val', 'best_acc_val']\n",
    "    df_best = best_val(df_best, df_val, df_test)\n",
    "    print(df_best[['name', 'best_loss_test', 'best_acc_test']])\n",
    "    print(df_best[['name', 'best_loss_val', 'best_acc_val']])\n",
    "    log_textfile(path_output +  modelname + 'multitask_test' + '.log', template.format(e, loss, acc, val_loss, val_acc, time_model, time_data))\n",
    "    df_best.to_csv(path_output +  modelname + 'multitask_test' + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 52176,
     "status": "ok",
     "timestamp": 1573636708782,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": -60
    },
    "id": "ENiEqcTM2o5b",
    "outputId": "7661277a-f2b1-485e-fbfb-85fc5e7d9c94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-explain\n",
      "  Downloading https://files.pythonhosted.org/packages/1e/1e/556ec1e91b100de61941a7c91589ce29be1afdc53d52658d2045ba84a7ab/tf_explain-0.1.0-py3-none-any.whl\n",
      "Collecting opencv-python>=4.1.0.25\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/7e/bd5425f4dacb73367fddc71388a47c1ea570839197c2bcad86478e565186/opencv_python-4.1.1.26-cp36-cp36m-manylinux1_x86_64.whl (28.7MB)\n",
      "\u001b[K     || 28.7MB 1.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python>=4.1.0.25->tf-explain) (1.17.3)\n",
      "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
      "Installing collected packages: opencv-python, tf-explain\n",
      "  Found existing installation: opencv-python 3.4.7.28\n",
      "    Uninstalling opencv-python-3.4.7.28:\n",
      "      Successfully uninstalled opencv-python-3.4.7.28\n",
      "Successfully installed opencv-python-4.1.1.26 tf-explain-0.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tf-explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 57697,
     "status": "ok",
     "timestamp": 1573636714920,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": -60
    },
    "id": "je8ZbBq3tZys",
    "outputId": "3c420738-3d47-44ed-9f75-25a268651cf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nilearn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/65/ba76e7cd544dafc28960e60b099d6f906a2096034c560158beaf2ff299bc/nilearn-0.5.2-py2.py3-none-any.whl (2.3MB)\n",
      "\r",
      "\u001b[K     |                               | 10kB 27.7MB/s eta 0:00:01\r",
      "\u001b[K     |                               | 20kB 1.1MB/s eta 0:00:03\r",
      "\u001b[K     |                               | 30kB 1.7MB/s eta 0:00:02\r",
      "\u001b[K     |                               | 40kB 1.1MB/s eta 0:00:03\r",
      "\u001b[K     |                               | 51kB 1.4MB/s eta 0:00:02\r",
      "\u001b[K     |                               | 61kB 1.6MB/s eta 0:00:02\r",
      "\u001b[K     |                               | 71kB 1.9MB/s eta 0:00:02\r",
      "\u001b[K     |                              | 81kB 2.2MB/s eta 0:00:02\r",
      "\u001b[K     |                              | 92kB 2.4MB/s eta 0:00:01\r",
      "\u001b[K     |                              | 102kB 1.8MB/s eta 0:00:02\r",
      "\u001b[K     |                              | 112kB 1.8MB/s eta 0:00:02\r",
      "\u001b[K     |                              | 122kB 1.8MB/s eta 0:00:02\r",
      "\u001b[K     |                              | 133kB 1.8MB/s eta 0:00:02\r",
      "\u001b[K     |                              | 143kB 1.8MB/s eta 0:00:02\r",
      "\u001b[K     |                              | 153kB 1.8MB/s eta 0:00:02\r",
      "\u001b[K     |                             | 163kB 1.8MB/s eta 0:00:02\r",
      "\u001b[K     |                             | 174kB 1.8MB/s eta 0:00:02\r",
      "\u001b[K     |                             | 184kB 1.8MB/s eta 0:00:02\r",
      "\u001b[K     |                             | 194kB 1.8MB/s eta 0:00:02\r",
      "\u001b[K     |                             | 204kB 1.8MB/s eta 0:00:02\r",
      "\u001b[K     |                             | 215kB 1.8MB/s eta 0:00:02\r",
      "\u001b[K     |                             | 225kB 1.8MB/s eta 0:00:02\r",
      "\u001b[K     |                            | 235kB 1.8MB/s eta 0:00:02\r",
      "\u001b[K     |                            | 245kB 1.8MB/s eta 0:00:02\r",
      "\u001b[K     |                            | 256kB 1.8MB/s eta 0:00:02\r",
      "\u001b[K     |                            | 266kB 1.8MB/s eta 0:00:02\r",
      "\u001b[K     |                            | 276kB 1.8MB/s eta 0:00:02\r",
      "\u001b[K     |                            | 286kB 1.8MB/s eta 0:00:02\r",
      "\u001b[K     |                            | 296kB 1.8MB/s eta 0:00:02\r",
      "\u001b[K     |                           | 307kB 1.8MB/s eta 0:00:02\r",
      "\u001b[K     |                           | 317kB 1.8MB/s eta 0:00:02\r",
      "\u001b[K     |                           | 327kB 1.8MB/s eta 0:00:02\r",
      "\u001b[K     |                           | 337kB 1.8MB/s eta 0:00:02\r",
      "\u001b[K     |                           | 348kB 1.8MB/s eta 0:00:02\r",
      "\u001b[K     |                           | 358kB 1.8MB/s eta 0:00:02\r",
      "\u001b[K     |                           | 368kB 1.8MB/s eta 0:00:02\r",
      "\u001b[K     |                          | 378kB 1.8MB/s eta 0:00:02\r",
      "\u001b[K     |                          | 389kB 1.8MB/s eta 0:00:02\r",
      "\u001b[K     |                          | 399kB 1.8MB/s eta 0:00:02\r",
      "\u001b[K     |                          | 409kB 1.8MB/s eta 0:00:02\r",
      "\u001b[K     |                          | 419kB 1.8MB/s eta 0:00:02\r",
      "\u001b[K     |                          | 430kB 1.8MB/s eta 0:00:02\r",
      "\u001b[K     |                          | 440kB 1.8MB/s eta 0:00:02\r",
      "\u001b[K     |                         | 450kB 1.8MB/s eta 0:00:02\r",
      "\u001b[K     |                         | 460kB 1.8MB/s eta 0:00:02\r",
      "\u001b[K     |                         | 471kB 1.8MB/s eta 0:00:02\r",
      "\u001b[K     |                         | 481kB 1.8MB/s eta 0:00:02\r",
      "\u001b[K     |                         | 491kB 1.8MB/s eta 0:00:02\r",
      "\u001b[K     |                         | 501kB 1.8MB/s eta 0:00:02\r",
      "\u001b[K     |                         | 512kB 1.8MB/s eta 0:00:02\r",
      "\u001b[K     |                        | 522kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                        | 532kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                        | 542kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                        | 552kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                        | 563kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                        | 573kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                        | 583kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                        | 593kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                       | 604kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                       | 614kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                       | 624kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                       | 634kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                       | 645kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                       | 655kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                       | 665kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                      | 675kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                      | 686kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                      | 696kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                      | 706kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                      | 716kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                      | 727kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                      | 737kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                     | 747kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                     | 757kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                     | 768kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                     | 778kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                     | 788kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                     | 798kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                     | 808kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                    | 819kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                    | 829kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                    | 839kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                    | 849kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                    | 860kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                    | 870kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                    | 880kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                   | 890kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                   | 901kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                   | 911kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                   | 921kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                   | 931kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                   | 942kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                   | 952kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                  | 962kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                  | 972kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                  | 983kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                  | 993kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                  | 1.0MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                  | 1.0MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                  | 1.0MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                  | 1.0MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                 | 1.0MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                 | 1.1MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                 | 1.1MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                 | 1.1MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                 | 1.1MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                 | 1.1MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                 | 1.1MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                | 1.1MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                | 1.1MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                | 1.1MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                | 1.1MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                | 1.2MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                | 1.2MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |                | 1.2MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |               | 1.2MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |               | 1.2MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |               | 1.2MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |               | 1.2MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |               | 1.2MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |               | 1.2MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |               | 1.2MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |              | 1.3MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |              | 1.3MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |              | 1.3MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |              | 1.3MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |              | 1.3MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |              | 1.3MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |              | 1.3MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |             | 1.3MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |             | 1.3MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |             | 1.4MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |             | 1.4MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |             | 1.4MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |             | 1.4MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |             | 1.4MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |            | 1.4MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |            | 1.4MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |            | 1.4MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |            | 1.4MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |            | 1.4MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |            | 1.5MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |            | 1.5MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |           | 1.5MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |           | 1.5MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |           | 1.5MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |           | 1.5MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |           | 1.5MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |           | 1.5MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |           | 1.5MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |           | 1.5MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |          | 1.6MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |          | 1.6MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |          | 1.6MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |          | 1.6MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |          | 1.6MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |          | 1.6MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |          | 1.6MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |         | 1.6MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |         | 1.6MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |         | 1.6MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |         | 1.7MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |         | 1.7MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |         | 1.7MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |         | 1.7MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |        | 1.7MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |        | 1.7MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |        | 1.7MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |        | 1.7MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |        | 1.7MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |        | 1.8MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |        | 1.8MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |       | 1.8MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |       | 1.8MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |       | 1.8MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |       | 1.8MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |       | 1.8MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |       | 1.8MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |       | 1.8MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |      | 1.8MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |      | 1.9MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |      | 1.9MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |      | 1.9MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |      | 1.9MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |      | 1.9MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |      | 1.9MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |     | 1.9MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |     | 1.9MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |     | 1.9MB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |     | 1.9MB 112kB/s eta 0:00:04\r",
      "\u001b[K     |     | 2.0MB 112kB/s eta 0:00:04\r",
      "\u001b[K     |     | 2.0MB 112kB/s eta 0:00:04\r",
      "\u001b[K     |     | 2.0MB 112kB/s eta 0:00:04\r",
      "\u001b[K     |     | 2.0MB 112kB/s eta 0:00:04\r",
      "\u001b[K     |    | 2.0MB 112kB/s eta 0:00:04\r",
      "\u001b[K     |    | 2.0MB 112kB/s eta 0:00:04\r",
      "\u001b[K     |    | 2.0MB 112kB/s eta 0:00:03\r",
      "\u001b[K     |    | 2.0MB 112kB/s eta 0:00:03\r",
      "\u001b[K     |    | 2.0MB 112kB/s eta 0:00:03\r",
      "\u001b[K     |    | 2.0MB 112kB/s eta 0:00:03\r",
      "\u001b[K     |    | 2.1MB 112kB/s eta 0:00:03\r",
      "\u001b[K     |   | 2.1MB 112kB/s eta 0:00:03\r",
      "\u001b[K     |   | 2.1MB 112kB/s eta 0:00:03\r",
      "\u001b[K     |   | 2.1MB 112kB/s eta 0:00:03\r",
      "\u001b[K     |   | 2.1MB 112kB/s eta 0:00:03\r",
      "\u001b[K     |   | 2.1MB 112kB/s eta 0:00:03\r",
      "\u001b[K     |   | 2.1MB 112kB/s eta 0:00:03\r",
      "\u001b[K     |   | 2.1MB 112kB/s eta 0:00:02\r",
      "\u001b[K     |  | 2.1MB 112kB/s eta 0:00:02\r",
      "\u001b[K     |  | 2.2MB 112kB/s eta 0:00:02\r",
      "\u001b[K     |  | 2.2MB 112kB/s eta 0:00:02\r",
      "\u001b[K     |  | 2.2MB 112kB/s eta 0:00:02\r",
      "\u001b[K     |  | 2.2MB 112kB/s eta 0:00:02\r",
      "\u001b[K     |  | 2.2MB 112kB/s eta 0:00:02\r",
      "\u001b[K     |  | 2.2MB 112kB/s eta 0:00:02\r",
      "\u001b[K     | | 2.2MB 112kB/s eta 0:00:02\r",
      "\u001b[K     | | 2.2MB 112kB/s eta 0:00:02\r",
      "\u001b[K     | | 2.2MB 112kB/s eta 0:00:02\r",
      "\u001b[K     | | 2.2MB 112kB/s eta 0:00:01\r",
      "\u001b[K     | | 2.3MB 112kB/s eta 0:00:01\r",
      "\u001b[K     | | 2.3MB 112kB/s eta 0:00:01\r",
      "\u001b[K     | | 2.3MB 112kB/s eta 0:00:01\r",
      "\u001b[K     || 2.3MB 112kB/s eta 0:00:01\r",
      "\u001b[K     || 2.3MB 112kB/s eta 0:00:01\r",
      "\u001b[K     || 2.3MB 112kB/s eta 0:00:01\r",
      "\u001b[K     || 2.3MB 112kB/s eta 0:00:01\r",
      "\u001b[K     || 2.3MB 112kB/s eta 0:00:01\r",
      "\u001b[K     || 2.3MB 112kB/s eta 0:00:01\r",
      "\u001b[K     || 2.3MB 112kB/s eta 0:00:01\r",
      "\u001b[K     || 2.4MB 112kB/s \n",
      "\u001b[?25hRequirement already satisfied: nibabel>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from nilearn) (2.3.3)\n",
      "Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from nibabel>=2.0.2->nilearn) (0.98)\n",
      "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from nibabel>=2.0.2->nilearn) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.6/dist-packages (from nibabel>=2.0.2->nilearn) (1.17.3)\n",
      "Installing collected packages: nilearn\n",
      "Successfully installed nilearn-0.5.2\n"
     ]
    }
   ],
   "source": [
    "!pip install nilearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 56450,
     "status": "ok",
     "timestamp": 1573636715232,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": -60
    },
    "id": "cv99Rx9vtUBF",
    "outputId": "ad64ddb7-7353-4df0-fe1e-f3b4ac938005"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from nilearn import plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import nilearn\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from nilearn.image import crop_img\n",
    "import os\n",
    "import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tyWmz3FstC8G"
   },
   "outputs": [],
   "source": [
    "a = next(iter(test_iter))\n",
    "t1 = (tf.cast(a['t1'], tf.float32)-t1_mean)/t1_std\n",
    "t2 = (a['t2']-t2_mean)/t2_std\n",
    "X = tf.concat([t1, t2], axis=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k1J0Fsn1Ijr2"
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(64,64,64,2), name='inputlayer123')\n",
    "a = model(inputs)['female']\n",
    "mm = Model(inputs=inputs, outputs=a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 54985,
     "status": "ok",
     "timestamp": 1573636716755,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": -60
    },
    "id": "1yvswMaT2lKD",
    "outputId": "bcc1195f-8702-4a2b-c41d-f264fb24143c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputlayer123 (InputLayer)   [(None, 64, 64, 64, 2)]   0         \n",
      "_________________________________________________________________\n",
      "my_dnn (MyDNN)               {'female': (None, 2), 'ra 2511944   \n",
      "=================================================================\n",
      "Total params: 2,511,944\n",
      "Trainable params: 2,500,744\n",
      "Non-trainable params: 11,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1327,
     "status": "ok",
     "timestamp": 1573636746552,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": -60
    },
    "id": "4rORUysK2cM3",
    "outputId": "03452a7a-6db7-4f87-b1be-f05fbdb00b2a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'my_dnn/lastconv_1/Identity:0' shape=(None, 4, 4, 4, 256) dtype=float32>"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm.get_layer('my_dnn').get_layer('lastconv_1').output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wf3u-dJ1PIT_"
   },
   "outputs": [],
   "source": [
    "from tf_explain.core.smoothgrad import SmoothGrad\n",
    "explainer = SmoothGrad()\n",
    "grid = explainer.explain((X[0:1], _), mm, 0, 20, 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4327,
     "status": "ok",
     "timestamp": 1573636753055,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": -60
    },
    "id": "SsBZysWOs34f",
    "outputId": "fe3a9a63-539e-4e88-a10b-57738791cd7f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAekAAADJCAYAAAAHFcoVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 475.2x187.2 with 4 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ppp = '/content/drive/My Drive/Capstone/05_Data/02_Sample_MRI/downsampled_resize/T2/sub-NDARINVFJJPAA2A_T2.nii.gz'\n",
    "org = nib.load(ppp)\n",
    "plotting.plot_anat(nilearn.image.new_img_like(ppp, grid, affine=None, copy_header=False))\n",
    "plotting.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-G7cjveLADUG"
   },
   "outputs": [],
   "source": [
    "from tf_explain.core.occlusion_sensitivity import OcclusionSensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nhXfjGsxADeD"
   },
   "outputs": [],
   "source": [
    "explainer = OcclusionSensitivity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_gGRXRJSADkG"
   },
   "outputs": [],
   "source": [
    "?? OcclusionSensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4225,
     "status": "error",
     "timestamp": 1573636765486,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": -60
    },
    "id": "Q1GJABrBBDOx",
    "outputId": "8b8bc278-991b-4a4a-dbb0-dea4c55ffeee"
   },
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-bddabab988a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m sensitivity_maps = np.array(\n\u001b[1;32m      2\u001b[0m             [\n\u001b[0;32m----> 3\u001b[0;31m                 \u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sensitivity_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m             ]\n\u001b[1;32m      5\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tf_explain/core/occlusion_sensitivity.py\u001b[0m in \u001b[0;36mget_sensitivity_map\u001b[0;34m(self, model, image, class_index, patch_size)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0msensitivity_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_x\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mconfidence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msensitivity_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemError\u001b[0m: new style getargs format but argument is not a tuple"
     ]
    }
   ],
   "source": [
    "sensitivity_maps = np.array(\n",
    "            [\n",
    "                explainer.get_sensitivity_map(mm, X[0], 0, 4)\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o3SM73D7BVZS"
   },
   "outputs": [],
   "source": [
    "image = X[0]\n",
    "patch_size = 4\n",
    "class_index=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1766,
     "status": "ok",
     "timestamp": 1573637561679,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": -60
    },
    "id": "mOYf3Oh0G42B",
    "outputId": "1c2d487b-7d54-4afa-efef-9b2242d897c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 64, 64, 2])"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yCP9mb_bC6SR"
   },
   "outputs": [],
   "source": [
    "def apply_grey_patch(image, top_left_x, top_left_y, top_left_z, patch_size):\n",
    "    \"\"\"\n",
    "    Replace a part of the image with a grey patch.\n",
    "    Args:\n",
    "        image (numpy.ndarray): Input image\n",
    "        top_left_x (int): Top Left X position of the applied box\n",
    "        top_left_y (int): Top Left Y position of the applied box\n",
    "        patch_size (int): Size of patch to apply\n",
    "    Returns:\n",
    "        numpy.ndarray: Patched image\n",
    "    \"\"\"\n",
    "    patched_image = np.array(image, copy=True)\n",
    "    patched_image[\n",
    "        top_left_x : top_left_x + patch_size, top_left_y : top_left_y + patch_size, top_left_z : top_left_z + patch_size, 0\n",
    "    ] = 0\n",
    "\n",
    "    return patched_image\n",
    "\n",
    "import math\n",
    "\n",
    "sensitivity_map = np.zeros((\n",
    "    math.ceil(image.shape[0] / patch_size),\n",
    "    math.ceil(image.shape[1] / patch_size),\n",
    "    math.ceil(image.shape[2] / patch_size),\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 41009,
     "status": "ok",
     "timestamp": 1573637656803,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": -60
    },
    "id": "urOT4dZqFzvY",
    "outputId": "2476c3b8-e514-40a0-b2a7-0e70bad97ad0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "1 4\n",
      "2 8\n",
      "3 12\n",
      "4 16\n",
      "5 20\n",
      "6 24\n",
      "7 28\n",
      "8 32\n",
      "9 36\n",
      "10 40\n",
      "11 44\n",
      "12 48\n",
      "13 52\n",
      "14 56\n",
      "15 60\n"
     ]
    }
   ],
   "source": [
    "for index_z, top_left_z in enumerate(range(0, image.shape[2], patch_size)):\n",
    "  print(index_z, top_left_z)\n",
    "  patches = [\n",
    "             apply_grey_patch(image, top_left_x, top_left_y, top_left_z, patch_size)\n",
    "             for index_x, top_left_x in enumerate(range(0, image.shape[0], patch_size))\n",
    "             for index_y, top_left_y in enumerate(range(0, image.shape[1], patch_size))\n",
    "            ]\n",
    "  coordinates = [\n",
    "               (index_y, index_x)\n",
    "               for index_x, _ in enumerate(range(0, image.shape[0], patch_size))\n",
    "               for index_y, _ in enumerate(range(0, image.shape[1], patch_size))\n",
    "               ]\n",
    "  predictions = mm.predict(np.array(patches), batch_size=1)\n",
    "  target_class_predictions = [prediction[class_index] for prediction in predictions]\n",
    "  for (index_y, index_x), confidence in zip(coordinates, target_class_predictions):\n",
    "    sensitivity_map[index_y, index_x, index_z] = 1 - confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TJNEmMOrG0Hi"
   },
   "outputs": [],
   "source": [
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YnQgVHssHqWX"
   },
   "outputs": [],
   "source": [
    "sm = resize(sensitivity_map, (64,64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8dT5GWoNHvKu"
   },
   "outputs": [],
   "source": [
    "heatmap = (sm - np.min(sm)) / (sm.max() - sm.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2692,
     "status": "ok",
     "timestamp": 1573638001081,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": -60
    },
    "id": "J53m22tPIIe-",
    "outputId": "53c0ebad-1730-47ff-9766-17bd8a5d0034"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/4AAABWCAYAAAB2O03TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/P/urvSw4hHWWAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1296x86.4 with 16 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "step = 4\n",
    "n_slices = int(64/4)\n",
    "i = 0\n",
    "n = 0\n",
    "data = (heatmap * 255).astype(\"uint8\")\n",
    "slice = 0\n",
    "fig, ax = plt.subplots(1, n_slices, figsize=[18, 1.2*1])\n",
    "for _ in range(n_slices):\n",
    "  #tmp_data = cv2.applyColorMap(cv2.cvtColor(data[:,:,slice], cv2.COLOR_GRAY2BGR), colormap)\n",
    "  ax[n].imshow(data[:,:,slice])\n",
    "  ax[n].set_xticks([])\n",
    "  ax[n].set_yticks([])\n",
    "  if i == 0:\n",
    "    ax[n].set_title(str(slice), color='r')\n",
    "  else:\n",
    "    ax[n].set_title('', color='r')\n",
    "  n += 1\n",
    "  slice += step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AvHj5mgfBTsU"
   },
   "outputs": [],
   "source": [
    "''def apply_grey_patch(image, top_left_x, top_left_y, top_left_z, patch_size):\n",
    "    \"\"\"\n",
    "    Replace a part of the image with a grey patch.\n",
    "    Args:\n",
    "        image (numpy.ndarray): Input image\n",
    "        top_left_x (int): Top Left X position of the applied box\n",
    "        top_left_y (int): Top Left Y position of the applied box\n",
    "        patch_size (int): Size of patch to apply\n",
    "    Returns:\n",
    "        numpy.ndarray: Patched image\n",
    "    \"\"\"\n",
    "    patched_image = np.array(image, copy=True)\n",
    "    patched_image[\n",
    "        top_left_y : top_left_y + patch_size, top_left_x : top_left_x + patch_size, top_left_z : top_left_z + patch_size, :\n",
    "    ] = 127.5\n",
    "\n",
    "    return patched_image\n",
    "\n",
    "import math\n",
    "\n",
    "sensitivity_map = np.zeros((\n",
    "    math.ceil(image.shape[0] / patch_size),\n",
    "    math.ceil(image.shape[1] / patch_size),\n",
    "    math.ceil(image.shape[2] / patch_size),\n",
    "))\n",
    "\n",
    "patches = [\n",
    "           apply_grey_patch(image, top_left_x, top_left_y, top_left_z, patch_size)\n",
    "           for index_x, top_left_x in enumerate(range(0, image.shape[0], patch_size))\n",
    "           for index_y, top_left_y in enumerate(range(0, image.shape[1], patch_size))\n",
    "           for index_z, top_left_z in enumerate(range(0, image.shape[2], patch_size))\n",
    "]\n",
    "\n",
    "coordinates = [\n",
    "               (index_y, index_x, index_z)\n",
    "               for index_x, _ in enumerate(range(0, image.shape[0], patch_size))\n",
    "               for index_y, _ in enumerate(range(0, image.shape[1], patch_size))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5tykySZbBhd6"
   },
   "outputs": [],
   "source": [
    "predictions = mm.predict(np.array(patches), batch_size=1)\n",
    "target_class_predictions = [\n",
    "                            prediction[class_index] for prediction in predictions\n",
    "]\n",
    "\n",
    "for (index_y, index_x), confidence in zip(coordinates, target_class_predictions):\n",
    "  sensitivity_map[index_y, index_x] = 1 - confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24896,
     "status": "ok",
     "timestamp": 1573636310007,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": -60
    },
    "id": "T7CP5XZmB5zk",
    "outputId": "51b20ba5-c4a1-437f-c380-1a091287d046"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32)"
      ]
     },
     "execution_count": 179,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivity_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2668,
     "status": "error",
     "timestamp": 1573635968909,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": -60
    },
    "id": "YSWQ9aLgADhm",
    "outputId": "2064a784-4ba7-48a1-fe7b-14423fb33eff"
   },
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-159-e6650cab4f21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tf_explain/core/occlusion_sensitivity.py\u001b[0m in \u001b[0;36mexplain\u001b[0;34m(self, validation_data, model, class_index, patch_size, colormap)\u001b[0m\n\u001b[1;32m     47\u001b[0m             [\n\u001b[1;32m     48\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sensitivity_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             ]\n\u001b[1;32m     51\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tf_explain/core/occlusion_sensitivity.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m             [\n\u001b[1;32m     48\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sensitivity_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             ]\n\u001b[1;32m     51\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tf_explain/core/occlusion_sensitivity.py\u001b[0m in \u001b[0;36mget_sensitivity_map\u001b[0;34m(self, model, image, class_index, patch_size)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0msensitivity_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_x\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mconfidence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msensitivity_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemError\u001b[0m: new style getargs format but argument is not a tuple"
     ]
    }
   ],
   "source": [
    "grid = explainer.explain((X[0:1], _), mm, 0, 20, 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GsN40IBZADbd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TJi2UZxHURxr"
   },
   "outputs": [],
   "source": [
    "from tf_explain.core.grad_cam import GradCAM\n",
    "explainer = GradCAM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JleqbVNFt61o"
   },
   "outputs": [],
   "source": [
    "??GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 928,
     "status": "ok",
     "timestamp": 1573635431699,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": -60
    },
    "id": "y9rvvybc68Zz",
    "outputId": "d733eeb0-9623-4abe-d37c-808b55b6abf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_dnn_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "re_lu_2 (ReLU)               multiple                  0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv3d_7 (Conv3D)            (None, 62, 62, 62, 32)    1760      \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 62, 62, 62, 32)    128       \n",
      "_________________________________________________________________\n",
      "conv3d_8 (Conv3D)            (None, 29, 29, 29, 64)    55360     \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 29, 29, 29, 64)    256       \n",
      "_________________________________________________________________\n",
      "conv3d_9 (Conv3D)            (None, 12, 12, 12, 128)   221312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 12, 12, 12, 128)   512       \n",
      "_________________________________________________________________\n",
      "lastconv_1 (Conv3D)          (None, 4, 4, 4, 256)      884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_51 (Batc (None, 4, 4, 4, 256)      1024      \n",
      "_________________________________________________________________\n",
      "sequential_45 (Sequential)   (None, 1)                 67073     \n",
      "_________________________________________________________________\n",
      "sequential_46 (Sequential)   (None, 1)                 67073     \n",
      "_________________________________________________________________\n",
      "sequential_40 (Sequential)   (None, 2)                 67330     \n",
      "_________________________________________________________________\n",
      "sequential_49 (Sequential)   (None, 1)                 67073     \n",
      "_________________________________________________________________\n",
      "sequential_42 (Sequential)   (None, 4)                 67844     \n",
      "_________________________________________________________________\n",
      "sequential_43 (Sequential)   (None, 8)                 68872     \n",
      "_________________________________________________________________\n",
      "sequential_44 (Sequential)   (None, 6)                 68358     \n",
      "_________________________________________________________________\n",
      "sequential_57 (Sequential)   (None, 1)                 67073     \n",
      "_________________________________________________________________\n",
      "sequential_51 (Sequential)   (None, 1)                 67073     \n",
      "_________________________________________________________________\n",
      "sequential_55 (Sequential)   (None, 1)                 67073     \n",
      "_________________________________________________________________\n",
      "sequential_50 (Sequential)   (None, 1)                 67073     \n",
      "_________________________________________________________________\n",
      "sequential_54 (Sequential)   (None, 1)                 67073     \n",
      "_________________________________________________________________\n",
      "sequential_52 (Sequential)   (None, 1)                 67073     \n",
      "_________________________________________________________________\n",
      "sequential_53 (Sequential)   (None, 1)                 67073     \n",
      "_________________________________________________________________\n",
      "sequential_56 (Sequential)   (None, 1)                 67073     \n",
      "_________________________________________________________________\n",
      "sequential_59 (Sequential)   (None, 1)                 67073     \n",
      "_________________________________________________________________\n",
      "sequential_58 (Sequential)   (None, 1)                 67073     \n",
      "_________________________________________________________________\n",
      "sequential_41 (Sequential)   (None, 5)                 68101     \n",
      "_________________________________________________________________\n",
      "sequential_47 (Sequential)   (None, 1)                 67073     \n",
      "_________________________________________________________________\n",
      "sequential_48 (Sequential)   (None, 1)                 67073     \n",
      "=================================================================\n",
      "Total params: 2,511,944\n",
      "Trainable params: 2,500,744\n",
      "Non-trainable params: 11,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1155,
     "status": "ok",
     "timestamp": 1573635511676,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": -60
    },
    "id": "Klr1s868--Pd",
    "outputId": "91ae4930-a29b-40e7-e6ba-b54f339f9de5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'my_dnn_2/sequential_40/Identity:0' shape=(None, 2) dtype=float32>"
      ]
     },
     "execution_count": 137,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm.get_layer('my_dnn_2').get_layer('sequential_40').output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A98V_pwSQRHe"
   },
   "outputs": [],
   "source": [
    "grad_model = tf.keras.models.Model(\n",
    "            [mm.inputs], [mm.get_layer('my_dnn_2').get_layer('lastconv_1').output, mm.get_layer('my_dnn_2').get_layer('sequential_40').output]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZtMPV1LRu-M9"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def image_to_uint_255(image):\n",
    "    \"\"\"\n",
    "    Convert float images to int 0-255 images.\n",
    "    Args:\n",
    "        image (numpy.ndarray): Input image. Can be either [0, 255], [0, 1], [-1, 1]\n",
    "    Returns:\n",
    "        numpy.ndarray:\n",
    "    \"\"\"\n",
    "    if image.dtype == np.uint8:\n",
    "        return image\n",
    "\n",
    "    if image.min() < 0:\n",
    "        image = (image + 1.0) / 2.0\n",
    "\n",
    "    return (image * 255).astype(\"uint8\")\n",
    "\n",
    "def heatmap_display(heatmap, original_image, colormap=cv2.COLORMAP_VIRIDIS):\n",
    "    \"\"\"\n",
    "    Apply a heatmap (as an np.ndarray) on top of an original image.\n",
    "    Args:\n",
    "        heatmap (numpy.ndarray): Array corresponding to the heatmap\n",
    "        original_image (numpy.ndarray): Image on which we apply the heatmap\n",
    "        colormap (int): OpenCV Colormap to use for heatmap visualization\n",
    "    Returns:\n",
    "        np.ndarray: Original image with heatmap applied\n",
    "    \"\"\"\n",
    "    heatmap = cv2.resize(heatmap, original_image.shape[0])\n",
    "\n",
    "    image = image_to_uint_255(original_image)\n",
    "\n",
    "    heatmap = (heatmap - np.min(heatmap)) / (heatmap.max() - heatmap.min())\n",
    "\n",
    "    heatmap = cv2.applyColorMap(\n",
    "        cv2.cvtColor((heatmap * 255).astype(\"uint8\"), cv2.COLOR_GRAY2BGR), colormap\n",
    "    )\n",
    "\n",
    "    output = cv2.addWeighted(cv2.cvtColor(image, cv2.COLOR_RGB2BGR), 0.7, heatmap, 1, 0)\n",
    "\n",
    "    return cv2.cvtColor(output, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0x7n6xNlVuCE"
   },
   "outputs": [],
   "source": [
    "colormap=cv2.COLORMAP_VIRIDIS\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  X_in = tf.cast(X[0:1], tf.float32)\n",
    "  conv_outputs, predictions = grad_model(X_in)\n",
    "  loss = predictions[:, 0]\n",
    "  tape.watch(loss)\n",
    "  tape.watch(conv_outputs)\n",
    "  grads = tape.gradient(loss, conv_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1109,
     "status": "ok",
     "timestamp": 1573635531488,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": -60
    },
    "id": "zkzfoc8651jB",
    "outputId": "57b5fff2-116a-4c75-cbf0-e4526ee4cf32"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 4, 4, 4, 256])"
      ]
     },
     "execution_count": 141,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1231,
     "status": "ok",
     "timestamp": 1573635624114,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": -60
    },
    "id": "yEUMgSwp_fvl",
    "outputId": "507004b5-d2bb-4890-fcc8-1b64f6bbf34d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 4, 4, 4, 256])"
      ]
     },
     "execution_count": 147,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NbK4gsGD5z8G"
   },
   "outputs": [],
   "source": [
    "guided_grads = (\n",
    "    tf.cast(conv_outputs > 0, \"float32\") * tf.cast(grads > 0, \"float32\") * grads\n",
    ")\n",
    "\n",
    "cams = GradCAM.generate_ponderated_output(conv_outputs, guided_grads)\n",
    "\n",
    "#heatmaps = np.array([\n",
    "#                     heatmap_display(cam.numpy(), image, colormap) \n",
    "#                     for cam, image in zip(cams, X[0:1])\n",
    "#                     ]\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GQRFygoO_lhl"
   },
   "outputs": [],
   "source": [
    "?? GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KJQ3A6D1vOga"
   },
   "outputs": [],
   "source": [
    "cam = cams[0].numpy()\n",
    "original_image = X[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 553,
     "status": "ok",
     "timestamp": 1573635677057,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": -60
    },
    "id": "jq6WwRHM_suQ",
    "outputId": "1260086f-78c7-4e90-83f5-29fbd499bd52"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4, 4)"
      ]
     },
     "execution_count": 149,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 994,
     "status": "ok",
     "timestamp": 1573635684025,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": -60
    },
    "id": "8-vBiYBL_uHv",
    "outputId": "38340d19-c523-4e35-c8a0-c02b2ed97298"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 64, 2)"
      ]
     },
     "execution_count": 150,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lf1EpM0huWkN"
   },
   "outputs": [],
   "source": [
    "image = image_to_uint_255(original_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RfWTQbouwPr6"
   },
   "outputs": [],
   "source": [
    "cam = (cam - np.min(cam)) / (cam.max() - cam.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3100,
     "status": "ok",
     "timestamp": 1573635695548,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": -60
    },
    "id": "Vc3-eSm_Wdtp",
    "outputId": "628281a8-8722-4854-fb6f-907dea010039"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAekAAADJCAYAAAAHFcoVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n68vp6qbqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 475.2x187.2 with 4 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ppp = '/content/drive/My Drive/Capstone/05_Data/02_Sample_MRI/downsampled_resize/T2/sub-NDARINVFJJPAA2A_T2.nii.gz'\n",
    "org = nib.load(ppp)\n",
    "plotting.plot_anat(nilearn.image.new_img_like(ppp, cam, affine=None, copy_header=False))\n",
    "plotting.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2499,
     "status": "ok",
     "timestamp": 1573632489896,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": -60
    },
    "id": "Zon4lQxqxy_g",
    "outputId": "e27ca556-4b0e-419d-f080-948504cda843"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/4AAABWCAYAAAB2O03TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyR3+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1296x86.4 with 16 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "step = 4\n",
    "n_slices = int(64/4)\n",
    "i = 0\n",
    "n = 0\n",
    "data = (cam * 255).astype(\"uint8\")\n",
    "slice = 0\n",
    "fig, ax = plt.subplots(1, n_slices, figsize=[18, 1.2*1])\n",
    "for _ in range(n_slices):\n",
    "  tmp_data = cv2.applyColorMap(cv2.cvtColor(data[:,:,slice], cv2.COLOR_GRAY2BGR), colormap)\n",
    "  ax[n].imshow(tmp_data)\n",
    "  ax[n].set_xticks([])\n",
    "  ax[n].set_yticks([])\n",
    "  if i == 0:\n",
    "    ax[n].set_title(str(slice), color='r')\n",
    "  else:\n",
    "    ax[n].set_title('', color='r')\n",
    "  n += 1\n",
    "  slice += step\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 850
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 988,
     "status": "ok",
     "timestamp": 1573632429787,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": -60
    },
    "id": "CswyaFSSzUT1",
    "outputId": "e23d5f93-8b96-493c-943a-220806dd2676"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[77, 71],\n",
       "        [77, 71],\n",
       "        [77, 71],\n",
       "        ...,\n",
       "        [77, 71],\n",
       "        [77, 71],\n",
       "        [77, 71]],\n",
       "\n",
       "       [[77, 71],\n",
       "        [77, 71],\n",
       "        [77, 71],\n",
       "        ...,\n",
       "        [77, 71],\n",
       "        [77, 71],\n",
       "        [77, 71]],\n",
       "\n",
       "       [[77, 71],\n",
       "        [77, 71],\n",
       "        [77, 71],\n",
       "        ...,\n",
       "        [77, 71],\n",
       "        [77, 71],\n",
       "        [77, 71]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[77, 71],\n",
       "        [77, 71],\n",
       "        [77, 71],\n",
       "        ...,\n",
       "        [77, 71],\n",
       "        [77, 71],\n",
       "        [77, 71]],\n",
       "\n",
       "       [[77, 71],\n",
       "        [77, 71],\n",
       "        [77, 71],\n",
       "        ...,\n",
       "        [77, 71],\n",
       "        [77, 71],\n",
       "        [77, 71]],\n",
       "\n",
       "       [[77, 71],\n",
       "        [77, 71],\n",
       "        [77, 71],\n",
       "        ...,\n",
       "        [77, 71],\n",
       "        [77, 71],\n",
       "        [77, 71]]], dtype=uint8)"
      ]
     },
     "execution_count": 105,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image[:,:,slice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 850
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1103,
     "status": "ok",
     "timestamp": 1573632359963,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": -60
    },
    "id": "sHi5Wa4OxzHv",
    "outputId": "f75dcc53-bb56-4004-c563-0732b9b00f95"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[133,  63,  66],\n",
       "        [133,  63,  66],\n",
       "        [133,  63,  66],\n",
       "        ...,\n",
       "        [133,  63,  66],\n",
       "        [133,  63,  66],\n",
       "        [133,  63,  66]],\n",
       "\n",
       "       [[133,  63,  66],\n",
       "        [133,  63,  66],\n",
       "        [133,  63,  66],\n",
       "        ...,\n",
       "        [133,  63,  66],\n",
       "        [133,  63,  66],\n",
       "        [133,  63,  66]],\n",
       "\n",
       "       [[133,  63,  66],\n",
       "        [133,  63,  66],\n",
       "        [133,  63,  66],\n",
       "        ...,\n",
       "        [133,  63,  66],\n",
       "        [133,  63,  66],\n",
       "        [133,  63,  66]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[133,  63,  66],\n",
       "        [133,  63,  66],\n",
       "        [133,  63,  66],\n",
       "        ...,\n",
       "        [133,  63,  66],\n",
       "        [133,  63,  66],\n",
       "        [133,  63,  66]],\n",
       "\n",
       "       [[133,  63,  66],\n",
       "        [133,  63,  66],\n",
       "        [133,  63,  66],\n",
       "        ...,\n",
       "        [133,  63,  66],\n",
       "        [133,  63,  66],\n",
       "        [133,  63,  66]],\n",
       "\n",
       "       [[133,  63,  66],\n",
       "        [133,  63,  66],\n",
       "        [133,  63,  66],\n",
       "        ...,\n",
       "        [133,  63,  66],\n",
       "        [133,  63,  66],\n",
       "        [133,  63,  66]]], dtype=uint8)"
      ]
     },
     "execution_count": 102,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.applyColorMap(cv2.cvtColor(data[:,:,slice], cv2.COLOR_GRAY2BGR), colormap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6j0saosJV0nl"
   },
   "outputs": [],
   "source": [
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1724,
     "status": "ok",
     "timestamp": 1573573601574,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": -60
    },
    "id": "9ll5ZhBYS0CC",
    "outputId": "da8f25d9-8618-4d94-a49c-6d12f26e452c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5602,
     "status": "ok",
     "timestamp": 1573573592894,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": -60
    },
    "id": "2l2aRBO0S0lH",
    "outputId": "8eb4d09c-aa88-4223-dc2d-872ff68cab0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nilearn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/65/ba76e7cd544dafc28960e60b099d6f906a2096034c560158beaf2ff299bc/nilearn-0.5.2-py2.py3-none-any.whl (2.3MB)\n",
      "\r",
      "\u001b[K     |                               | 10kB 27.8MB/s eta 0:00:01\r",
      "\u001b[K     |                               | 20kB 6.2MB/s eta 0:00:01\r",
      "\u001b[K     |                               | 30kB 8.9MB/s eta 0:00:01\r",
      "\u001b[K     |                               | 40kB 5.9MB/s eta 0:00:01\r",
      "\u001b[K     |                               | 51kB 7.1MB/s eta 0:00:01\r",
      "\u001b[K     |                               | 61kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |                               | 71kB 9.6MB/s eta 0:00:01\r",
      "\u001b[K     |                              | 81kB 10.8MB/s eta 0:00:01\r",
      "\u001b[K     |                              | 92kB 11.9MB/s eta 0:00:01\r",
      "\u001b[K     |                              | 102kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                              | 112kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                              | 122kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                              | 133kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                              | 143kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                              | 153kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                             | 163kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                             | 174kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                             | 184kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                             | 194kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                             | 204kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                             | 215kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                             | 225kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                            | 235kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                            | 245kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                            | 256kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                            | 266kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                            | 276kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                            | 286kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                            | 296kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                           | 307kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                           | 317kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                           | 327kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                           | 337kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                           | 348kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                           | 358kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                           | 368kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                          | 378kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                          | 389kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                          | 399kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                          | 409kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                          | 419kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                          | 430kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                          | 440kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                         | 450kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                         | 460kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                         | 471kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                         | 481kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                         | 491kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                         | 501kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                         | 512kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                        | 522kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                        | 532kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                        | 542kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                        | 552kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                        | 563kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                        | 573kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                        | 583kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                        | 593kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                       | 604kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                       | 614kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                       | 624kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                       | 634kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                       | 645kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                       | 655kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                       | 665kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                      | 675kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                      | 686kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                      | 696kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                      | 706kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                      | 716kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                      | 727kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                      | 737kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                     | 747kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                     | 757kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                     | 768kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                     | 778kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                     | 788kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                     | 798kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                     | 808kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                    | 819kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                    | 829kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                    | 839kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                    | 849kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                    | 860kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                    | 870kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                    | 880kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                   | 890kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                   | 901kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                   | 911kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                   | 921kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                   | 931kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                   | 942kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                   | 952kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                  | 962kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                  | 972kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                  | 983kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                  | 993kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                  | 1.0MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                  | 1.0MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                  | 1.0MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                  | 1.0MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                 | 1.0MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                 | 1.1MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                 | 1.1MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                 | 1.1MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                 | 1.1MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                 | 1.1MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                 | 1.1MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                | 1.1MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                | 1.1MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                | 1.1MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                | 1.1MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                | 1.2MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                | 1.2MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |                | 1.2MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |               | 1.2MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |               | 1.2MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |               | 1.2MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |               | 1.2MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |               | 1.2MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |               | 1.2MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |               | 1.2MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |              | 1.3MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |              | 1.3MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |              | 1.3MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |              | 1.3MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |              | 1.3MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |              | 1.3MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |              | 1.3MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |             | 1.3MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |             | 1.3MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |             | 1.4MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |             | 1.4MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |             | 1.4MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |             | 1.4MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |             | 1.4MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |            | 1.4MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |            | 1.4MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |            | 1.4MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |            | 1.4MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |            | 1.4MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |            | 1.5MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |            | 1.5MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |           | 1.5MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |           | 1.5MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |           | 1.5MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |           | 1.5MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |           | 1.5MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |           | 1.5MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |           | 1.5MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |           | 1.5MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |          | 1.6MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |          | 1.6MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |          | 1.6MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |          | 1.6MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |          | 1.6MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |          | 1.6MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |          | 1.6MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |         | 1.6MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |         | 1.6MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |         | 1.6MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |         | 1.7MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |         | 1.7MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |         | 1.7MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |         | 1.7MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |        | 1.7MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |        | 1.7MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |        | 1.7MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |        | 1.7MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |        | 1.7MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |        | 1.8MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |        | 1.8MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |       | 1.8MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |       | 1.8MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |       | 1.8MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |       | 1.8MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |       | 1.8MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |       | 1.8MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |       | 1.8MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |      | 1.8MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |      | 1.9MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |      | 1.9MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |      | 1.9MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |      | 1.9MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |      | 1.9MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |      | 1.9MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |     | 1.9MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |     | 1.9MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |     | 1.9MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |     | 1.9MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |     | 2.0MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |     | 2.0MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |     | 2.0MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |     | 2.0MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |    | 2.0MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |    | 2.0MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |    | 2.0MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |    | 2.0MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |    | 2.0MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |    | 2.0MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |    | 2.1MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |   | 2.1MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |   | 2.1MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |   | 2.1MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |   | 2.1MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |   | 2.1MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |   | 2.1MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |   | 2.1MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |  | 2.1MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |  | 2.2MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |  | 2.2MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |  | 2.2MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |  | 2.2MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |  | 2.2MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |  | 2.2MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     | | 2.2MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     | | 2.2MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     | | 2.2MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     | | 2.2MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     | | 2.3MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     | | 2.3MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     | | 2.3MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     || 2.3MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     || 2.3MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     || 2.3MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     || 2.3MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     || 2.3MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     || 2.3MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     || 2.3MB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     || 2.4MB 9.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: nibabel>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from nilearn) (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.6/dist-packages (from nibabel>=2.0.2->nilearn) (1.17.3)\n",
      "Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from nibabel>=2.0.2->nilearn) (0.98)\n",
      "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from nibabel>=2.0.2->nilearn) (1.12.0)\n",
      "Installing collected packages: nilearn\n",
      "Successfully installed nilearn-0.5.2\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fmCx2QDeTgV5"
   },
   "outputs": [],
   "source": [
    "ppp = '/content/drive/My Drive/Capstone/05_Data/02_Sample_MRI/downsampled_resize/T2/sub-NDARINVFJJPAA2A_T2.nii.gz'\n",
    "org = nib.load(ppp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3aOZOBl7UAYf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2719,
     "status": "ok",
     "timestamp": 1573573909666,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": -60
    },
    "id": "x9nuB0SiS3lG",
    "outputId": "da89a83a-9b5d-4286-c265-f9b6d614177e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAekAAADJCAYAAAAHFcoVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<Figure size 475.2x187.2 with 4 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dSeow2ZMTSM4"
   },
   "outputs": [],
   "source": [
    "nilearn.image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1068,
     "status": "error",
     "timestamp": 1573570989091,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": -60
    },
    "id": "aUUkRh73Ikou",
    "outputId": "9280f05b-2745-4b4f-eb3c-22a9bb5c2ee3"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-5f54dad89d21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0m_keras_api_gauge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;31m# initializing _distribution_strategy here since it is possible to call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m       \u001b[0;31m# Subclassed network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_subclassed_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_no_legacy_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_init_subclassed_network\u001b[0;34m(self, name, **kwargs)\u001b[0m\n\u001b[1;32m    376\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_init_subclassed_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_call_fn_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_base_init\u001b[0;34m(self, name, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     generic_utils.validate_kwargs(kwargs, {'trainable', 'dtype', 'dynamic',\n\u001b[0;32m--> 197\u001b[0;31m                                            'autocast'})\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# Object to store all thread local layer properties.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mvalidate_kwargs\u001b[0;34m(kwargs, allowed_kwargs, error_message)\u001b[0m\n\u001b[1;32m    597\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: ('Keyword argument not understood:', 'inputs')"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "mm = tf.keras.Model(inputs=inputs, output=inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5iG2jty7ItI6"
   },
   "outputs": [],
   "source": [
    "aaa = model.fc['female']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1101,
     "status": "ok",
     "timestamp": 1573572176029,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": -60
    },
    "id": "rBkxNGXJMm3f",
    "outputId": "8f9443a0-ce63-4b6b-cfd6-5bdcb191d7f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x7f9c981c3828>"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa.layers[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1594,
     "status": "error",
     "timestamp": 1573571926766,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": -60
    },
    "id": "R7pvBAzEMgIb",
    "outputId": "b674a27f-9b52-49c7-d0d6-bda6bebe1508"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-82b832867aa3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'female'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'children'"
     ]
    }
   ],
   "source": [
    "list(model.fc['female'].children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aQ6iuJbGEym7"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "\n",
    "class WrapperMyDNN(Model):\n",
    "  def __init__(self, model):\n",
    "    super(WrapperMyDNN, self).__init__()\n",
    "    self.model = model\n",
    "    #self.output = self.model.fc['female'].layers[-1]\n",
    "  \n",
    "  def call(self, x):\n",
    "    x_tmp = self.model(x)\n",
    "    return(x_tmp['female'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S4Qim0gN0Lua"
   },
   "outputs": [],
   "source": [
    "?? Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IbySX5WM0F4G"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "\n",
    "class MyDNN2(Model):\n",
    "  def __init__(self, cat_cols, num_cols, **kwargs):\n",
    "    super(MyDNN2, self).__init__(**kwargs)\n",
    "    self.cat_cols = cat_cols\n",
    "    self.num_cols = num_cols\n",
    "    self.ac = tf.keras.layers.ReLU()\n",
    "    self.maxpool = tf.keras.layers.MaxPool3D(pool_size=(2, 2, 2), data_format='channels_last')\n",
    "    self.conv1 = tf.keras.layers.Conv3D(\n",
    "        filters = 32,\n",
    "        kernel_size = 3,\n",
    "        padding='valid',\n",
    "        data_format='channels_last',\n",
    "        input_shape = (64,64,64,2)\n",
    "    )\n",
    "    self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "    self.conv2 = tf.keras.layers.Conv3D(\n",
    "        filters = 64,\n",
    "        kernel_size = 3,\n",
    "        padding='valid',\n",
    "        data_format='channels_last'\n",
    "    )\n",
    "    self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "    self.conv3 = tf.keras.layers.Conv3D(\n",
    "        filters = 128,\n",
    "        kernel_size = 3,\n",
    "        padding='valid',\n",
    "        data_format='channels_last'\n",
    "    )\n",
    "    self.bn3 = tf.keras.layers.BatchNormalization()\n",
    "    self.conv4 = tf.keras.layers.Conv3D(\n",
    "        filters = 256,\n",
    "        kernel_size = 3,\n",
    "        padding='valid',\n",
    "        data_format='channels_last'\n",
    "    )\n",
    "    self.bn4 = tf.keras.layers.BatchNormalization()\n",
    "    self.fc = {}\n",
    "    for k in list(self.cat_cols.keys()):\n",
    "      self.fc[k] = tf.keras.Sequential([\n",
    "                                        tf.keras.layers.Dense(256, activation='relu'),\n",
    "                                        tf.keras.layers.BatchNormalization(),\n",
    "                                        tf.keras.layers.Dense(self.cat_cols[k], activation='softmax')\n",
    "                                        ])\n",
    "    for i in range(len(self.num_cols)):\n",
    "      self.fc[self.num_cols[i]] = tf.keras.Sequential([\n",
    "                                        tf.keras.layers.Dense(256, activation='relu'),\n",
    "                                        tf.keras.layers.BatchNormalization(),\n",
    "                                        tf.keras.layers.Dense(1)\n",
    "                                        ])\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = self.bn1(x)\n",
    "    x = self.ac(x)\n",
    "    x = self.maxpool(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.bn2(x)\n",
    "    x = self.ac(x)\n",
    "    x = self.maxpool(x)\n",
    "    x = self.conv3(x)\n",
    "    x = self.bn3(x)\n",
    "    x = self.ac(x)\n",
    "    x = self.maxpool(x)\n",
    "    x = self.conv4(x)\n",
    "    x = self.bn4(x)\n",
    "    x = self.ac(x)\n",
    "    x = tf.keras.layers.GlobalAveragePooling3D()(x)\n",
    "    out = {}\n",
    "    for k in list(self.fc.keys()):\n",
    "      out[k] = self.fc[k](x)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DytC-LQsPZSd"
   },
   "outputs": [],
   "source": [
    "model2 = WrapperMyDNN(model)\n",
    "a = next(iter(test_iter))\n",
    "t1 = (tf.cast(a['t1'], tf.float32)-t1_mean)/t1_std\n",
    "t2 = (a['t2']-t2_mean)/t2_std\n",
    "X = tf.concat([t1, t2], axis=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1130,
     "status": "error",
     "timestamp": 1573572569092,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": -60
    },
    "id": "-FnN0VNHOuHC",
    "outputId": "e39d17e4-1629-4f90-d4e3-e8341a78c956"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-14884ea50a93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36moutput\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1574\u001b[0m     \"\"\"\n\u001b[1;32m   1575\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1576\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Layer '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' has no inbound nodes.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1577\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_node_attribute_at_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'output_tensors'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'output'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Layer wrapper_my_dnn_2 has no inbound nodes."
     ]
    }
   ],
   "source": [
    "model2.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 477
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4623,
     "status": "error",
     "timestamp": 1573572511655,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": -60
    },
    "id": "1HQqLXqWWxXJ",
    "outputId": "1422a528-c7a4-4e68-db58-1485075ac412"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-b10e0ba2c512>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_explain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmoothgrad\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSmoothGrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mexplainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSmoothGrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tf_explain/core/smoothgrad.py\u001b[0m in \u001b[0;36mexplain\u001b[0;34m(self, validation_data, model, class_index, num_samples, noise)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         smoothed_gradients = SmoothGrad.get_averaged_gradients(\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mnoisy_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         )\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    492\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1820\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1822\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1823\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2150\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2151\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2039\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2041\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2042\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    913\u001b[0m                                           converted_func)\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    903\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 905\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: in converted code:\n    relative to /usr/local/lib/python3.6/dist-packages:\n\n    tf_explain/core/smoothgrad.py:85 get_averaged_gradients  *\n        num_classes = model.output.shape[1]\n    tensorflow_core/python/keras/engine/base_layer.py:1576 output\n        raise AttributeError('Layer ' + self.name + ' has no inbound nodes.')\n\n    AttributeError: Layer wrapper_my_dnn_2 has no inbound nodes.\n"
     ]
    }
   ],
   "source": [
    "from tf_explain.core.smoothgrad import SmoothGrad\n",
    "explainer = SmoothGrad()\n",
    "grid = explainer.explain((X, None), model2, 1, 20, 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cP7thtjAqunC"
   },
   "outputs": [],
   "source": [
    "output = []\n",
    "output.append(['colname', 'mse'])\n",
    "for col in num_cols:\n",
    "  mean = test_df[col].mean()\n",
    "  mse_norm = np.mean(np.square(test_df[col]-mean))\n",
    "  output.append([col, mse_norm])\n",
    "\n",
    "for col in list(cat_cols.keys()):\n",
    "  mean = test_df[col].value_counts().idxmax()\n",
    "  mse_norm = np.mean(test_df[col]==mean)\n",
    "  output.append([col, mse_norm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rw_KzTw6Q4wr"
   },
   "outputs": [],
   "source": [
    "a = next(iter(test_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ben3zkRr32sD"
   },
   "outputs": [],
   "source": [
    "t1 = (tf.cast(a['t1'], tf.float32)-t1_mean)/t1_std\n",
    "t2 = (a['t2']-t2_mean)/t2_std\n",
    "X = tf.concat([t1, t2], axis=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1117,
     "status": "ok",
     "timestamp": 1573490357380,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": -60
    },
    "id": "622IROlaVWVu",
    "outputId": "9b50cdce-6128-4fc7-9757-80d1fdce306f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([8, 64, 64, 64, 2])"
      ]
     },
     "execution_count": 73,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1122,
     "status": "ok",
     "timestamp": 1573490251609,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": -60
    },
    "id": "ynswVv2MUwZi",
    "outputId": "276f09a5-4318-4fa2-a029-34a2a8c4dd3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_dnn_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "re_lu_2 (ReLU)               multiple                  0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv3d_8 (Conv3D)            multiple                  1760      \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc multiple                  128       \n",
      "_________________________________________________________________\n",
      "conv3d_9 (Conv3D)            multiple                  55360     \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc multiple                  256       \n",
      "_________________________________________________________________\n",
      "conv3d_10 (Conv3D)           multiple                  221312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc multiple                  512       \n",
      "_________________________________________________________________\n",
      "conv3d_11 (Conv3D)           multiple                  884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_51 (Batc multiple                  1024      \n",
      "_________________________________________________________________\n",
      "sequential_45 (Sequential)   multiple                  67073     \n",
      "_________________________________________________________________\n",
      "sequential_46 (Sequential)   multiple                  67073     \n",
      "_________________________________________________________________\n",
      "sequential_40 (Sequential)   multiple                  67330     \n",
      "_________________________________________________________________\n",
      "sequential_49 (Sequential)   multiple                  67073     \n",
      "_________________________________________________________________\n",
      "sequential_42 (Sequential)   multiple                  67844     \n",
      "_________________________________________________________________\n",
      "sequential_43 (Sequential)   multiple                  68872     \n",
      "_________________________________________________________________\n",
      "sequential_44 (Sequential)   multiple                  68358     \n",
      "_________________________________________________________________\n",
      "sequential_57 (Sequential)   multiple                  67073     \n",
      "_________________________________________________________________\n",
      "sequential_51 (Sequential)   multiple                  67073     \n",
      "_________________________________________________________________\n",
      "sequential_55 (Sequential)   multiple                  67073     \n",
      "_________________________________________________________________\n",
      "sequential_50 (Sequential)   multiple                  67073     \n",
      "_________________________________________________________________\n",
      "sequential_54 (Sequential)   multiple                  67073     \n",
      "_________________________________________________________________\n",
      "sequential_52 (Sequential)   multiple                  67073     \n",
      "_________________________________________________________________\n",
      "sequential_53 (Sequential)   multiple                  67073     \n",
      "_________________________________________________________________\n",
      "sequential_56 (Sequential)   multiple                  67073     \n",
      "_________________________________________________________________\n",
      "sequential_59 (Sequential)   multiple                  67073     \n",
      "_________________________________________________________________\n",
      "sequential_58 (Sequential)   multiple                  67073     \n",
      "_________________________________________________________________\n",
      "sequential_41 (Sequential)   multiple                  68101     \n",
      "_________________________________________________________________\n",
      "sequential_47 (Sequential)   multiple                  67073     \n",
      "_________________________________________________________________\n",
      "sequential_48 (Sequential)   multiple                  67073     \n",
      "=================================================================\n",
      "Total params: 2,511,944\n",
      "Trainable params: 2,500,744\n",
      "Non-trainable params: 11,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 477
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5540,
     "status": "error",
     "timestamp": 1573490614301,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": -60
    },
    "id": "2RwCwYigS0UO",
    "outputId": "7f1ede39-9d2b-40f1-eed3-f1b72b4573f9"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-b10e0ba2c512>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_explain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmoothgrad\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSmoothGrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mexplainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSmoothGrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tf_explain/core/smoothgrad.py\u001b[0m in \u001b[0;36mexplain\u001b[0;34m(self, validation_data, model, class_index, num_samples, noise)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         smoothed_gradients = SmoothGrad.get_averaged_gradients(\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mnoisy_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         )\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    492\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1820\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1822\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1823\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2150\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2151\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2039\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2041\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2042\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    913\u001b[0m                                           converted_func)\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    903\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 905\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: in converted code:\n    relative to /usr/local/lib/python3.6/dist-packages:\n\n    tf_explain/core/smoothgrad.py:85 get_averaged_gradients  *\n        num_classes = model.output.shape[1]\n    tensorflow_core/python/keras/engine/base_layer.py:1576 output\n        raise AttributeError('Layer ' + self.name + ' has no inbound nodes.')\n\n    AttributeError: Layer wrapper_my_dnn_4 has no inbound nodes.\n"
     ]
    }
   ],
   "source": [
    "from tf_explain.core.smoothgrad import SmoothGrad\n",
    "explainer = SmoothGrad()\n",
    "grid = explainer.explain((X, None), model2, 1, 20, 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3698,
     "status": "ok",
     "timestamp": 1573490096976,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": -60
    },
    "id": "b033WUfMTy_S",
    "outputId": "e71254e5-e55f-488b-a2ce-5ce5f7117b5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 01_ProgressReport\t  05_Data\t\t     09_SimpleDLModel\n",
      " 02_Projects\t\t  06_Ideas\t\t     10_DenseNet\n",
      " 03_Background_Research   07_AutoFocusLayer\t     cat.jpg\n",
      " 04_Weekly_Meetings\t  08_TFRecords_Experiments  'Important notes.gdoc'\n"
     ]
    }
   ],
   "source": [
    "!ls /content/drive/My\\ Drive/Capstone/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 935
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8973,
     "status": "ok",
     "timestamp": 1573490110703,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": -60
    },
    "id": "-RohbTtqS4qd",
    "outputId": "497f7261-9a93-4151-a55e-d449ecfaa40b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "IMAGE_PATH = '/content/drive/My Drive/Capstone/cat.jpg'\n",
    "\n",
    "model_res = tf.keras.applications.vgg16.VGG16(weights='imagenet', include_top=True)\n",
    "\n",
    "img = tf.keras.preprocessing.image.load_img(IMAGE_PATH, target_size=(224, 224))\n",
    "img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "\n",
    "model_res.summary()\n",
    "data = ([img], None)\n",
    "\n",
    "tabby_cat_class_index = 281\n",
    "explainer = SmoothGrad()\n",
    "# Compute SmoothGrad on VGG16\n",
    "grid = explainer.explain(data, model_res, tabby_cat_class_index, 20, 1.)\n",
    "explainer.save(grid, '.', 'smoothgrad.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8kJ4t1IgT_FF"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "files.download('./smoothgrad.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zDC5mlR9UpWo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1594,
     "status": "ok",
     "timestamp": 1573489069509,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": -60
    },
    "id": "-dvYng1iQBUQ",
    "outputId": "b4ddf708-f070-43a7-938b-12bc92419372"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([8, 2])"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1585,
     "status": "ok",
     "timestamp": 1573488955519,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": -60
    },
    "id": "7JMy-Zmg3_8t",
    "outputId": "a0d77624-e846-451d-c8f8-84f587118f0b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=116151, shape=(8, 2), dtype=float32, numpy=\n",
       "array([[0.53804183, 0.46195817],\n",
       "       [0.4839683 , 0.51603174],\n",
       "       [0.7212447 , 0.2787553 ],\n",
       "       [0.5602738 , 0.43972617],\n",
       "       [0.653129  , 0.346871  ],\n",
       "       [0.5561602 , 0.44383982],\n",
       "       [0.6063691 , 0.39363095],\n",
       "       [0.7199904 , 0.2800096 ]], dtype=float32)>"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'model.call(X)['female']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mIYd0IsfiKER"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(output).to_csv(path_output + 'baseline.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 811,
     "status": "ok",
     "timestamp": 1572985942408,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": 300
    },
    "id": "j3kFZEWAQ5XU",
    "outputId": "c9769171-4ee2-4e40-d803-fcde7a266188"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subjectkey</th>\n",
       "      <th>age</th>\n",
       "      <th>female</th>\n",
       "      <th>race.ethnicity</th>\n",
       "      <th>high.educ</th>\n",
       "      <th>income</th>\n",
       "      <th>abcd_site</th>\n",
       "      <th>vol</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>BMI</th>\n",
       "      <th>nihtbx_fluidcomp_uncorrected</th>\n",
       "      <th>nihtbx_cryst_uncorrected</th>\n",
       "      <th>nihtbx_pattern_uncorrected</th>\n",
       "      <th>nihtbx_picture_uncorrected</th>\n",
       "      <th>nihtbx_list_uncorrected</th>\n",
       "      <th>nihtbx_flanker_uncorrected</th>\n",
       "      <th>nihtbx_picvocab_uncorrected</th>\n",
       "      <th>nihtbx_cardsort_uncorrected</th>\n",
       "      <th>nihtbx_totalcomp_uncorrected</th>\n",
       "      <th>nihtbx_reading_uncorrected</th>\n",
       "      <th>high.educ_group</th>\n",
       "      <th>income_group</th>\n",
       "      <th>BMI_norm</th>\n",
       "      <th>age_norm</th>\n",
       "      <th>vol_norm</th>\n",
       "      <th>weight_norm</th>\n",
       "      <th>height_norm</th>\n",
       "      <th>nihtbx_fluidcomp_uncorrected_norm</th>\n",
       "      <th>nihtbx_cryst_uncorrected_norm</th>\n",
       "      <th>nihtbx_pattern_uncorrected_norm</th>\n",
       "      <th>nihtbx_picture_uncorrected_norm</th>\n",
       "      <th>nihtbx_list_uncorrected_norm</th>\n",
       "      <th>nihtbx_flanker_uncorrected_norm</th>\n",
       "      <th>nihtbx_picvocab_uncorrected_norm</th>\n",
       "      <th>nihtbx_cardsort_uncorrected_norm</th>\n",
       "      <th>nihtbx_totalcomp_uncorrected_norm</th>\n",
       "      <th>nihtbx_reading_uncorrected_norm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>married</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7008</td>\n",
       "      <td>0.7008</td>\n",
       "      <td>0.7008</td>\n",
       "      <td>0.7008</td>\n",
       "      <td>0.7008</td>\n",
       "      <td>0.7008</td>\n",
       "      <td>0.7008</td>\n",
       "      <td>0.7008</td>\n",
       "      <td>0.7008</td>\n",
       "      <td>0.7008</td>\n",
       "      <td>0.7008</td>\n",
       "      <td>0.7008</td>\n",
       "      <td>0.7008</td>\n",
       "      <td>0.7008</td>\n",
       "      <td>0.7008</td>\n",
       "      <td>0.7008</td>\n",
       "      <td>0.7008</td>\n",
       "      <td>0.7008</td>\n",
       "      <td>0.7008</td>\n",
       "      <td>0.7008</td>\n",
       "      <td>0.7008</td>\n",
       "      <td>0.7008</td>\n",
       "      <td>0.7008</td>\n",
       "      <td>0.7008</td>\n",
       "      <td>0.7008</td>\n",
       "      <td>0.7008</td>\n",
       "      <td>0.7008</td>\n",
       "      <td>0.7008</td>\n",
       "      <td>0.7008</td>\n",
       "      <td>0.7008</td>\n",
       "      <td>0.7008</td>\n",
       "      <td>0.7008</td>\n",
       "      <td>0.7008</td>\n",
       "      <td>0.7008</td>\n",
       "      <td>0.7008</td>\n",
       "      <td>0.7008</td>\n",
       "      <td>0.7008</td>\n",
       "      <td>0.7008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.0808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.1328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         subjectkey  ...  nihtbx_reading_uncorrected_norm\n",
       "married              ...                                 \n",
       "0            0.7008  ...                           0.7008\n",
       "1            0.0056  ...                           0.0056\n",
       "2            0.0808  ...                           0.0808\n",
       "3            0.0336  ...                           0.0336\n",
       "4            0.1328  ...                           0.1328\n",
       "5            0.0464  ...                           0.0464\n",
       "\n",
       "[6 rows x 38 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.groupby(['married']).count() / val_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1403,
     "status": "ok",
     "timestamp": 1572884554781,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": 300
    },
    "id": "6ivDV4iphO9A",
    "outputId": "43969338-33ff-44f8-e207-2b03cf78d9a2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>colname</td>\n",
       "      <td>mse</td>\n",
       "      <td>mse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>age_norm</td>\n",
       "      <td>0.980777</td>\n",
       "      <td>0.980777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vol_norm</td>\n",
       "      <td>0.945484</td>\n",
       "      <td>0.945484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>weight_norm</td>\n",
       "      <td>0.889882</td>\n",
       "      <td>0.889882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>height_norm</td>\n",
       "      <td>1.0227</td>\n",
       "      <td>1.0227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nihtbx_fluidcomp_uncorrected_norm</td>\n",
       "      <td>0.984666</td>\n",
       "      <td>0.984666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nihtbx_cryst_uncorrected_norm</td>\n",
       "      <td>1.03023</td>\n",
       "      <td>1.03023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nihtbx_pattern_uncorrected_norm</td>\n",
       "      <td>0.969314</td>\n",
       "      <td>0.969314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nihtbx_picture_uncorrected_norm</td>\n",
       "      <td>0.95365</td>\n",
       "      <td>0.95365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nihtbx_list_uncorrected_norm</td>\n",
       "      <td>1.00613</td>\n",
       "      <td>1.00613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>nihtbx_flanker_uncorrected_norm</td>\n",
       "      <td>1.01185</td>\n",
       "      <td>1.01185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>nihtbx_picvocab_uncorrected_norm</td>\n",
       "      <td>1.04232</td>\n",
       "      <td>1.04232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>nihtbx_cardsort_uncorrected_norm</td>\n",
       "      <td>0.97436</td>\n",
       "      <td>0.97436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>nihtbx_totalcomp_uncorrected_norm</td>\n",
       "      <td>0.994743</td>\n",
       "      <td>0.994743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>nihtbx_reading_uncorrected_norm</td>\n",
       "      <td>0.996083</td>\n",
       "      <td>0.996083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0         1      loss\n",
       "0                             colname       mse       mse\n",
       "1                            age_norm  0.980777  0.980777\n",
       "2                            vol_norm  0.945484  0.945484\n",
       "3                         weight_norm  0.889882  0.889882\n",
       "4                         height_norm    1.0227    1.0227\n",
       "5   nihtbx_fluidcomp_uncorrected_norm  0.984666  0.984666\n",
       "6       nihtbx_cryst_uncorrected_norm   1.03023   1.03023\n",
       "7     nihtbx_pattern_uncorrected_norm  0.969314  0.969314\n",
       "8     nihtbx_picture_uncorrected_norm   0.95365   0.95365\n",
       "9        nihtbx_list_uncorrected_norm   1.00613   1.00613\n",
       "10    nihtbx_flanker_uncorrected_norm   1.01185   1.01185\n",
       "11   nihtbx_picvocab_uncorrected_norm   1.04232   1.04232\n",
       "12   nihtbx_cardsort_uncorrected_norm   0.97436   0.97436\n",
       "13  nihtbx_totalcomp_uncorrected_norm  0.994743  0.994743\n",
       "14    nihtbx_reading_uncorrected_norm  0.996083  0.996083"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(pd.DataFrame(output), df, left_on=0, right_on=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3TEP3PWnc4-g"
   },
   "outputs": [],
   "source": [
    "cols = ['nihtbx_fluidcomp_uncorrected', 'nihtbx_cryst_uncorrected', \n",
    "              'nihtbx_pattern_uncorrected', 'nihtbx_picture_uncorrected', \n",
    "              'nihtbx_list_uncorrected', 'nihtbx_flanker_uncorrected',\n",
    "              'nihtbx_picvocab_uncorrected', 'nihtbx_cardsort_uncorrected',\n",
    "              'nihtbx_totalcomp_uncorrected', 'nihtbx_reading_uncorrected']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GG6ZMe11hqLf"
   },
   "outputs": [],
   "source": [
    "output = []\n",
    "output.append(['colname', 'mse'])\n",
    "for col in cols:\n",
    "  mean = val_df[col].mean()\n",
    "  mse_norm = np.mean(np.square(val_df[col]-mean))\n",
    "  output.append([col, mse_norm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 793,
     "status": "ok",
     "timestamp": 1572621420115,
     "user": {
      "displayName": "Benedikt Dietmar Schifferer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDViwxKXBjVKZfXMWGuXrQ48D62bye6HNutAOX0=s64",
      "userId": "06737229821528734971"
     },
     "user_tz": 240
    },
    "id": "6YJAmfWtil8q",
    "outputId": "1cf07203-3ec7-4448-e8dd-1e7be5ab8636"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>colname</td>\n",
       "      <td>mse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nihtbx_fluidcomp_uncorrected</td>\n",
       "      <td>0.738561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nihtbx_cryst_uncorrected</td>\n",
       "      <td>0.634104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nihtbx_pattern_uncorrected</td>\n",
       "      <td>0.872343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nihtbx_picture_uncorrected</td>\n",
       "      <td>0.874858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nihtbx_list_uncorrected</td>\n",
       "      <td>0.796694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nihtbx_flanker_uncorrected</td>\n",
       "      <td>0.832563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nihtbx_picvocab_uncorrected</td>\n",
       "      <td>0.673517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nihtbx_cardsort_uncorrected</td>\n",
       "      <td>0.837488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nihtbx_totalcomp_uncorrected</td>\n",
       "      <td>0.615594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>nihtbx_reading_uncorrected</td>\n",
       "      <td>0.732034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0         1\n",
       "0                        colname       mse\n",
       "1   nihtbx_fluidcomp_uncorrected  0.738561\n",
       "2       nihtbx_cryst_uncorrected  0.634104\n",
       "3     nihtbx_pattern_uncorrected  0.872343\n",
       "4     nihtbx_picture_uncorrected  0.874858\n",
       "5        nihtbx_list_uncorrected  0.796694\n",
       "6     nihtbx_flanker_uncorrected  0.832563\n",
       "7    nihtbx_picvocab_uncorrected  0.673517\n",
       "8    nihtbx_cardsort_uncorrected  0.837488\n",
       "9   nihtbx_totalcomp_uncorrected  0.615594\n",
       "10    nihtbx_reading_uncorrected  0.732034"
      ]
     },
     "execution_count": 111,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OViFTzBKioI2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AExg0jq563dS"
   },
   "outputs": [],
   "source": [
    "model.get_layer('lastconv')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "06_SimpleDL_MultiTask_Valid.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
